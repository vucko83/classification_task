{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-901ecf7c38c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m                           \u001b[0mnormalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                           \u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Confusion matrix'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m                           cmap=plt.cm.Blues):\n\u001b[0m\u001b[1;32m      5\u001b[0m     \"\"\"\n\u001b[1;32m      6\u001b[0m     \u001b[0mThis\u001b[0m \u001b[0mfunction\u001b[0m \u001b[0mprints\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mplots\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mconfusion\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_curve as prc\n",
    "\n",
    "\n",
    "#from sklearn.model_selection import \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import itertools\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read and Prepare Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read data\n",
    "df=pd.read_csv('Data-Classification.txt')\n",
    "\n",
    "\n",
    "# Create Train and Test Splits\n",
    "X=df.iloc[:,1:] \n",
    "y=df.iloc[:,0] # Separate input and output\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.33, random_state=42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['A', 'C', 'B'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark Models and Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithms "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "benchmark_algorithms ={\n",
    "    'LR' : LogisticRegression(),\n",
    "    'RF' : RandomForestClassifier(),\n",
    "    'KNN': KNeighborsClassifier()\n",
    " }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.scorer import make_scorer\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "def mine_roc_auc(y_true, y_pred, average='micro'):\n",
    "    '''\n",
    "    Wrapper for AUC type measures (auroc and auprc),\n",
    "    because they demand input in form of dummy variables\n",
    "    '''\n",
    "    y_true_dummy = pd.get_dummies(y_true)\n",
    "    y_pred_dummy = pd.get_dummies(y_pred)\n",
    "    return (roc_auc_score(y_true_dummy, y_pred_dummy, average=average))\n",
    "\n",
    "# Scoring dict to be used in all evaluations\n",
    "scoring = {\n",
    "           'au_prc_macro': make_scorer(mine_roc_auc, average='macro'),\n",
    "           'au_prc_micro': make_scorer(mine_roc_auc, average='macro'),\n",
    "           'f1_macro': 'f1_macro',\n",
    "           'f1_micro': 'f1_micro',\n",
    "           'precision_macro': 'precision_macro',\n",
    "           'precision_micro': 'precision_micro',\n",
    "           'accuracy': 'accuracy',\n",
    "          }\n",
    "\n",
    "###!!!!!! Micro Macro Explanation https://datascience.stackexchange.com/questions/15989/micro-average-vs-macro-average-performance-in-a-multiclass-classification-settin/16001\n",
    "### !!! plotting cross val cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "#from sklearn.metrics import recall_score\n",
    "\n",
    "models_dict = {}\n",
    "scores_dict = {}\n",
    "\n",
    "for model_name, model in benchmark_algorithms.items():\n",
    "    \n",
    "    scores = cross_validate(model, X_train, y_train, scoring=scoring,\n",
    "                            cv=5, return_train_score=False)\n",
    "    scores_aggregated= { measure: '%.3f' % round(np.average(values),3)\n",
    "                                  #{'avg': '%.3f' % round(np.average(values),3)}\\\n",
    "                                   #'std': '%.2f' % round(np.std(values),2)} \\\n",
    "                                    for measure, values in scores.items()}\n",
    "    scores_dict.update({model_name:scores_aggregated})\n",
    "    \n",
    "    fitted_model = model.fit(X_train, y_train)\n",
    "    models_dict.update({model_name:fitted_model})\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KNN</th>\n",
       "      <th>LR</th>\n",
       "      <th>RF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fit_time</th>\n",
       "      <td>0.003</td>\n",
       "      <td>0.114</td>\n",
       "      <td>0.036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_time</th>\n",
       "      <td>0.053</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_accuracy</th>\n",
       "      <td>0.394</td>\n",
       "      <td>0.946</td>\n",
       "      <td>0.891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_au_prc_macro</th>\n",
       "      <td>0.546</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_au_prc_micro</th>\n",
       "      <td>0.546</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_f1_macro</th>\n",
       "      <td>0.388</td>\n",
       "      <td>0.946</td>\n",
       "      <td>0.891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_f1_micro</th>\n",
       "      <td>0.394</td>\n",
       "      <td>0.946</td>\n",
       "      <td>0.891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_precision_macro</th>\n",
       "      <td>0.397</td>\n",
       "      <td>0.947</td>\n",
       "      <td>0.893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_precision_micro</th>\n",
       "      <td>0.394</td>\n",
       "      <td>0.946</td>\n",
       "      <td>0.891</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        KNN     LR     RF\n",
       "fit_time              0.003  0.114  0.036\n",
       "score_time            0.053  0.014  0.026\n",
       "test_accuracy         0.394  0.946  0.891\n",
       "test_au_prc_macro     0.546  0.960  0.918\n",
       "test_au_prc_micro     0.546  0.960  0.918\n",
       "test_f1_macro         0.388  0.946  0.891\n",
       "test_f1_micro         0.394  0.946  0.891\n",
       "test_precision_macro  0.397  0.947  0.893\n",
       "test_precision_micro  0.394  0.946  0.891"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(scores_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusions={}\n",
    "for name, model in models_dict.items():\n",
    "    y_predicted = model.predict(X_test)\n",
    "    confusions.update({name: confusion_matrix(y_predicted, y_test)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[109,   1,   5],\n",
       "       [  0, 108,   1],\n",
       "       [  4,   0, 102]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusions['LR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        title = title+' (Normalized)'\n",
    "\n",
    "    #print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['A', 'B', 'C'], dtype=object)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls=np.unique(y_train)\n",
    "cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'KNN': KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "            metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "            weights='uniform'),\n",
       " 'LR': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "           penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "           verbose=0, warm_start=False),\n",
       " 'RF': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "             max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "             oob_score=False, random_state=None, verbose=0,\n",
       "             warm_start=False)}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAngAAALqCAYAAACmOSlyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11d0717b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "arrangement=[(321,322), (323, 324), (325, 326)]\n",
    "i=0\n",
    "fig=plt.figure(1, figsize=(10,10))\n",
    "fig.suptitle('Confusion Matrices', fontsize=16, y=1.03)\n",
    "for name, conf in confusions.items(): \n",
    "    ax1=plt.subplot(arrangement[i][0])\n",
    "    plot_confusion_matrix(cm =conf, classes = cls, normalize=False, title = name)\n",
    "\n",
    "    plt.subplot(arrangement[i][1])\n",
    "    plot_confusion_matrix(cm =conf, classes = cls, normalize=True, title = name + ' Confusion')\n",
    "    fig.subplots_adjust(wspace=0.05, hspace=0.3)\n",
    "    i+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig.savefig('Confusions_Benchmark')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'KNN': {'fit_time': {'avg': '0.003', 'std': '0.00'},\n",
       "  'score_time': {'avg': '0.041', 'std': '0.00'},\n",
       "  'test_accuracy': {'avg': '0.394', 'std': '0.04'},\n",
       "  'test_au_prc_macro': {'avg': '0.546', 'std': '0.03'},\n",
       "  'test_au_prc_micro': {'avg': '0.546', 'std': '0.03'},\n",
       "  'test_f1_macro': {'avg': '0.388', 'std': '0.05'},\n",
       "  'test_f1_micro': {'avg': '0.394', 'std': '0.04'},\n",
       "  'test_precision_macro': {'avg': '0.397', 'std': '0.04'},\n",
       "  'test_precision_micro': {'avg': '0.394', 'std': '0.04'},\n",
       "  'train_accuracy': {'avg': '0.616', 'std': '0.01'},\n",
       "  'train_au_prc_macro': {'avg': '0.712', 'std': '0.01'},\n",
       "  'train_au_prc_micro': {'avg': '0.712', 'std': '0.01'},\n",
       "  'train_f1_macro': {'avg': '0.612', 'std': '0.01'},\n",
       "  'train_f1_micro': {'avg': '0.616', 'std': '0.01'},\n",
       "  'train_precision_macro': {'avg': '0.628', 'std': '0.01'},\n",
       "  'train_precision_micro': {'avg': '0.616', 'std': '0.01'}},\n",
       " 'LR': {'fit_time': {'avg': '0.127', 'std': '0.05'},\n",
       "  'score_time': {'avg': '0.014', 'std': '0.00'},\n",
       "  'test_accuracy': {'avg': '0.946', 'std': '0.02'},\n",
       "  'test_au_prc_macro': {'avg': '0.960', 'std': '0.01'},\n",
       "  'test_au_prc_micro': {'avg': '0.960', 'std': '0.01'},\n",
       "  'test_f1_macro': {'avg': '0.946', 'std': '0.02'},\n",
       "  'test_f1_micro': {'avg': '0.946', 'std': '0.02'},\n",
       "  'test_precision_macro': {'avg': '0.947', 'std': '0.02'},\n",
       "  'test_precision_micro': {'avg': '0.946', 'std': '0.02'},\n",
       "  'train_accuracy': {'avg': '0.983', 'std': '0.01'},\n",
       "  'train_au_prc_macro': {'avg': '0.987', 'std': '0.00'},\n",
       "  'train_au_prc_micro': {'avg': '0.987', 'std': '0.00'},\n",
       "  'train_f1_macro': {'avg': '0.983', 'std': '0.01'},\n",
       "  'train_f1_micro': {'avg': '0.983', 'std': '0.01'},\n",
       "  'train_precision_macro': {'avg': '0.983', 'std': '0.01'},\n",
       "  'train_precision_micro': {'avg': '0.983', 'std': '0.01'}},\n",
       " 'RF': {'fit_time': {'avg': '0.036', 'std': '0.01'},\n",
       "  'score_time': {'avg': '0.021', 'std': '0.00'},\n",
       "  'test_accuracy': {'avg': '0.896', 'std': '0.04'},\n",
       "  'test_au_prc_macro': {'avg': '0.922', 'std': '0.03'},\n",
       "  'test_au_prc_micro': {'avg': '0.922', 'std': '0.03'},\n",
       "  'test_f1_macro': {'avg': '0.896', 'std': '0.04'},\n",
       "  'test_f1_micro': {'avg': '0.896', 'std': '0.04'},\n",
       "  'test_precision_macro': {'avg': '0.898', 'std': '0.04'},\n",
       "  'test_precision_micro': {'avg': '0.896', 'std': '0.04'},\n",
       "  'train_accuracy': {'avg': '0.997', 'std': '0.00'},\n",
       "  'train_au_prc_macro': {'avg': '0.998', 'std': '0.00'},\n",
       "  'train_au_prc_micro': {'avg': '0.998', 'std': '0.00'},\n",
       "  'train_f1_macro': {'avg': '0.997', 'std': '0.00'},\n",
       "  'train_f1_micro': {'avg': '0.997', 'std': '0.00'},\n",
       "  'train_precision_macro': {'avg': '0.997', 'std': '0.00'},\n",
       "  'train_precision_micro': {'avg': '0.997', 'std': '0.00'}}}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection and Parameter Optimization\n",
    "\n",
    "Since benchmark model (Logistic regression) gave good results in terms of different validation measure (both on training and test data), further analyses will be focused on finding:\n",
    "- More interpretable solutions\n",
    "- More robust solutions (in terms of generalization)\n",
    "\n",
    "For this purpose, hyper-parameters of models will be optimized as well as feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check if it can be done with simple Pipeline()\n",
    "pipe = Pipeline([\n",
    "    ('normalize', MinMaxScaler(feature_range=(1,2))),\n",
    "    ('reduce_dim', PCA()),\n",
    "    ('classify', RidgeClassifier())\n",
    "     ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Classifiers and parameter ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Heuristics that define algorithm hyper parameter ranges based on number of samples and number of features\n",
    "'''\n",
    "\n",
    "def n_features_range(n_samples=100, m_features=3, m_n_ratio=1):\n",
    "    '''\n",
    "    Used for definition of algorithm parameters based on available number of features\n",
    "     and samples, after feature selection.\n",
    "     \n",
    "    It is used for definition of grid search params through a pipeline\n",
    "     \n",
    "    :param n_samples: number of samples in the dataframe/matrix\n",
    "    :param m_features: number of features after feature selection\n",
    "    :param m_n_ratio: maximal number of features relative to number of samples\n",
    "    \n",
    "    :return: range of numbers of features used for param optimization in algorithms \n",
    "    '''\n",
    "\n",
    "    max_features = int(round(n_samples / m_n_ratio))\n",
    "    if m_features < max_features:\n",
    "        max_features = m_features\n",
    "\n",
    "    if m_features == 1:\n",
    "        min_features = 1\n",
    "    else:\n",
    "        min_features = 2\n",
    "\n",
    "    step_size = int(round(np.log2(max_features)))\n",
    "\n",
    "    param_range = [a for a in range(min_features, max_features, step_size)]\n",
    "\n",
    "    if param_range[-1] < max_features:\n",
    "        param_range.append(max_features)\n",
    "\n",
    "    return param_range\n",
    "\n",
    "def nn_size(m_features):\n",
    "    half = int(np.ceil((m_features + 1) / 2))\n",
    "    quarter = int(np.ceil((m_features + 1) / 4))\n",
    "    size = [(quarter,), (half,)]\n",
    "    return (size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rf_param_dict(name='classify', estimators=[RandomForestClassifier()], n_samples=1000, m_features=[15]):\n",
    "    dict={\n",
    "        name: estimators,\n",
    "        name + '__' + 'n_estimators': range(20, 101, 20),\n",
    "        name + '__' + 'max_features': n_features_range(n_samples, m_features),\n",
    "        name + '__' + 'min_samples_leaf': np.arange(0.01, 0.03, 0.05),\n",
    "        name + '__' + 'max_depth': range(2, 11, 2)\n",
    "    }\n",
    "    return (dict)\n",
    "\n",
    "def ann_param_dict(name='classify', estimators=[MLPClassifier()], n_samples=100, m_features=15):\n",
    "    dict={\n",
    "        name: estimators,\n",
    "        name + '__' + 'learning_rate': ['constant'],\n",
    "        name + '__' + 'momentum': [0.01, 0.05, 0.1, 0.2, 0.4, 0.6, 0.8, 0.9],\n",
    "        name + '__' + 'max_iter': [100000],\n",
    "        name + '__' + 'hidden_layer_sizes': nn_size(m_features)\n",
    "    }\n",
    "    return (dict)\n",
    "\n",
    "def knn_param_dict(name='classify', estimators=[KNeighborsClassifier()], n_samples=1000, m_features=15): # Check this if needed\n",
    "    dict={\n",
    "        name: estimators,\n",
    "        name + '__' + 'n_neighbors': [3, 5, 7],    \n",
    "    }\n",
    "    return (dict)\n",
    "\n",
    "def logistic_param_dict(name='classify', estimators=[LogisticRegression()], n_samples=1000, m_features=15): # Check this if needed\n",
    "    dict={\n",
    "        name: estimators,\n",
    "        name + '__' + 'penalty': ['l1', 'l2'],\n",
    "        name + '__' + 'C': [0.01, 0.03, 0.1, 0.5, 0.8, 1],\n",
    "        name + '__' + 'max_iter': [10000],\n",
    "        name + '__' + 'solver': ['saga']\n",
    "        # check for multinomial\n",
    "    }\n",
    "    return (dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Feature Selectors and Parameter ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.decomposition import NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_params_pca_nmf(name='reduce_dim', reducers=[PCA(), NMF()], n_samples=100, m_features=[5, 10, 15, 20, 25, 30], funcs=[]):\n",
    "    params=[]\n",
    "\n",
    "    for func in funcs.values():\n",
    "        for m in m_features:\n",
    "            dict = {\n",
    "                name: reducers,\n",
    "                name+'__'+'n_components':[m]\n",
    "            }\n",
    "            dict.update(func(m_features=m))\n",
    "\n",
    "            params.append(dict.copy())\n",
    "    return (params)\n",
    "\n",
    "def create_params_select_from_model(name='reduce_dim', reducers=[SelectKBest('f_classif'), SelectKBest('mutual_info_classif')], n_samples=100, m_features=[5, 10, 15, 20, 25, 30], funcs=[]):\n",
    "    params=[]\n",
    "    for func in funcs.values(): \n",
    "        for m in m_features:\n",
    "            dict = {\n",
    "                name: reducers,\n",
    "                name+'__'+'k':[m]\n",
    "            }\n",
    "            dict.update(func(m_features=m))\n",
    "\n",
    "            params.append(dict.copy())\n",
    "    return (params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Create Param Grid for Hyper Parameter and Feature Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# set algorithms param grics\n",
    "algorithms= {'logistic':logistic_param_dict, 'ann': ann_param_dict, 'knn' : knn_param_dict, 'rf': rf_param_dict}\n",
    "\n",
    "# take number of samples and feature number range \n",
    "n_samples = X_train.shape[0]\n",
    "m_features = [5, 10, 15, 20, 25, 30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pars1 = create_params_pca_nmf(name='reduce_dim', reducers=[PCA(), NMF()], n_samples=n_samples,\\\n",
    "                              m_features=m_features, funcs=algorithms)\n",
    "pars2 = create_params_select_from_model(name='reduce_dim', reducers=[SelectKBest(score_func=f_classif),\\\n",
    "                SelectKBest(score_func=mutual_info_classif)], n_samples=n_samples, m_features=m_features, funcs=algorithms)\n",
    "pars = pars1 + pars2 # Concatenate lists with param grids\n",
    "\n",
    "### !!!! one more round of experimtnts with added params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "search=GridSearchCV(estimator = pipe, param_grid = pars, scoring=scoring, refit='au_prc_macro', cv=5, n_jobs=4,\\\n",
    "                    return_train_score=False).fit(X_train, y_train)\n",
    "#!!Git set and work https://github.com/codepath/ios_guides/wiki/Using-Git-with-Terminal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CVResults=search.cv_results_\n",
    "log_df=pd.DataFrame(CVResults) # log2Pandas\n",
    "log_df.sort_values('mean_test_au_prc_macro', ascending=False).to_csv('results.csv') # Sort and store for analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 729,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('reduce_dim', PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)), ('classify', RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,\n",
       "        max_iter=None, normalize=False, random_state=None, solver='auto',\n",
       "        tol=0.001))]),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid=[{'reduce_dim': [SelectKBest(k=10, score_func=<function f_classif at 0x118c10510>), SelectKBest(k=5, score_func=<function mutual_info_classif at 0x118d43158>)], 'classify__max_iter': [100000], 'reduce_dim__k': [5], 'classify': [MLPClassifier(activation='relu', alpha=0.0001, batch_size='au...fy__learning_rate': ['constant'], 'classify__momentum': [0.01, 0.05, 0.1, 0.2, 0.4, 0.6, 0.8, 0.9]}],\n",
       "       pre_dispatch='2*n_jobs', refit='au_prc_macro',\n",
       "       return_train_score=False,\n",
       "       scoring={'accuracy': 'accuracy', 'f1_micro': 'f1_micro', 'au_prc_macro': make_scorer(mine_roc_auc, average=macro), 'f1_macro': 'f1_macro', 'precision_micro': 'precision_micro', 'precision_macro': 'precision_macro', 'au_prc_micro': make_scorer(mine_roc_auc, average=macro)},\n",
       "       verbose=0)"
      ]
     },
     "execution_count": 729,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearchCV log analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipe.set_params(**a).fit(X_train, y_train).predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 718,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([ 0.0109551 ,  0.65677562,  0.0816834 ,  0.18826756,  0.24026718,\n",
       "         0.16335015,  0.01153383,  0.27298131,  0.08154159,  0.36969075,\n",
       "         0.00660005,  0.28755422,  0.02615285,  0.27820807,  0.08988695,\n",
       "         0.29298196,  0.16692843,  0.17311163,  0.04517407,  0.22064333,\n",
       "         0.00697832,  0.12571726,  0.040417  ,  0.22772217,  0.12976303,\n",
       "         0.2157124 ,  0.07344737,  0.17564259,  0.07472625,  0.15537663,\n",
       "         0.00716376,  0.1576632 ,  0.04687395,  0.13711381,  0.06568961,\n",
       "         0.12925415,  0.17258077,  0.12471476,  0.13563619,  0.2234344 ,\n",
       "         0.24317284,  0.26047168,  0.00657377,  0.21804714,  0.03444161,\n",
       "         0.12741942,  0.10297322,  0.12763743,  0.01481915,  0.12234325,\n",
       "         0.0062202 ,  0.12607584,  0.00753055,  0.13711395,  0.00710359,\n",
       "         0.12383962,  0.05037103,  0.21970382,  0.00606103,  0.12771301,\n",
       "         0.00937676,  0.13243017,  0.01241732,  0.13323517]),\n",
       " 'mean_score_time': array([ 0.02240043,  0.01795359,  0.01630759,  0.01696029,  0.02143884,\n",
       "         0.01735582,  0.02367043,  0.01936865,  0.01070681,  0.01187663,\n",
       "         0.01167455,  0.0129436 ,  0.0128592 ,  0.01262555,  0.01188798,\n",
       "         0.01171412,  0.01838255,  0.01676741,  0.01594934,  0.01527562,\n",
       "         0.0122323 ,  0.01284041,  0.01202197,  0.01263518,  0.01326981,\n",
       "         0.01120758,  0.01249857,  0.0134594 ,  0.01246018,  0.01307559,\n",
       "         0.01332273,  0.01446295,  0.01244583,  0.013551  ,  0.01325817,\n",
       "         0.0128808 ,  0.01179924,  0.01167078,  0.01174979,  0.0124372 ,\n",
       "         0.01123381,  0.01268497,  0.01100984,  0.01157446,  0.01482801,\n",
       "         0.01291361,  0.01365485,  0.0119926 ,  0.01290979,  0.01141677,\n",
       "         0.01300139,  0.01280494,  0.01335006,  0.01348481,  0.01208477,\n",
       "         0.01302662,  0.01169357,  0.01263676,  0.01194458,  0.0124382 ,\n",
       "         0.01168036,  0.01250319,  0.01782923,  0.0133544 ]),\n",
       " 'mean_test_accuracy': array([ 0.28358209,  0.38059701,  0.32089552,  0.3358209 ,  0.36567164,\n",
       "         0.36567164,  0.35074627,  0.36567164,  0.38059701,  0.36567164,\n",
       "         0.30597015,  0.41044776,  0.34328358,  0.38059701,  0.34328358,\n",
       "         0.38059701,  0.42537313,  0.36567164,  0.28358209,  0.41044776,\n",
       "         0.3358209 ,  0.3880597 ,  0.35074627,  0.41791045,  0.32835821,\n",
       "         0.35820896,  0.35820896,  0.35074627,  0.3358209 ,  0.3880597 ,\n",
       "         0.35074627,  0.34328358,  0.32089552,  0.35820896,  0.3358209 ,\n",
       "         0.30597015,  0.36567164,  0.29850746,  0.3358209 ,  0.3358209 ,\n",
       "         0.35074627,  0.35074627,  0.23880597,  0.31343284,  0.29104478,\n",
       "         0.35074627,  0.37313433,  0.31343284,  0.38059701,  0.36567164,\n",
       "         0.30597015,  0.35074627,  0.31343284,  0.41791045,  0.28358209,\n",
       "         0.39552239,  0.35074627,  0.31343284,  0.29850746,  0.34328358,\n",
       "         0.35820896,  0.3880597 ,  0.38059701,  0.31343284]),\n",
       " 'mean_test_au_prc_macro': array([ 0.5       ,  0.54626709,  0.52934905,  0.48165446,  0.5       ,\n",
       "         0.55165643,  0.4795329 ,  0.5       ,  0.49336915,  0.51956604,\n",
       "         0.5       ,  0.55226293,  0.50044447,  0.50762332,  0.51956604,\n",
       "         0.53966306,  0.57150747,  0.52104283,  0.4707544 ,  0.43118931,\n",
       "         0.5       ,  0.54349063,  0.49211557,  0.61126552,  0.51511194,\n",
       "         0.47341136,  0.54775296,  0.5       ,  0.54645503,  0.52141198,\n",
       "         0.53055048,  0.49969964,  0.49021698,  0.51161969,  0.5       ,\n",
       "         0.5       ,  0.49205726,  0.54368494,  0.49436496,  0.47777656,\n",
       "         0.51038373,  0.53679854,  0.50273968,  0.48006392,  0.43889905,\n",
       "         0.4868202 ,  0.49103058,  0.50636304,  0.55124091,  0.52179434,\n",
       "         0.47863183,  0.55733648,  0.52140631,  0.56493458,  0.48411452,\n",
       "         0.53299137,  0.5       ,  0.49085035,  0.51028628,  0.49826394,\n",
       "         0.49543652,  0.47093223,  0.5678773 ,  0.5       ]),\n",
       " 'mean_test_au_prc_micro': array([ 0.5       ,  0.54626709,  0.52934905,  0.48165446,  0.5       ,\n",
       "         0.55165643,  0.4795329 ,  0.5       ,  0.49336915,  0.51956604,\n",
       "         0.5       ,  0.55226293,  0.50044447,  0.50762332,  0.51956604,\n",
       "         0.53966306,  0.57150747,  0.52104283,  0.4707544 ,  0.43118931,\n",
       "         0.5       ,  0.54349063,  0.49211557,  0.61126552,  0.51511194,\n",
       "         0.47341136,  0.54775296,  0.5       ,  0.54645503,  0.52141198,\n",
       "         0.53055048,  0.49969964,  0.49021698,  0.51161969,  0.5       ,\n",
       "         0.5       ,  0.49205726,  0.54368494,  0.49436496,  0.47777656,\n",
       "         0.51038373,  0.53679854,  0.50273968,  0.48006392,  0.43889905,\n",
       "         0.4868202 ,  0.49103058,  0.50636304,  0.55124091,  0.52179434,\n",
       "         0.47863183,  0.55733648,  0.52140631,  0.56493458,  0.48411452,\n",
       "         0.53299137,  0.5       ,  0.49085035,  0.51028628,  0.49826394,\n",
       "         0.49543652,  0.47093223,  0.5678773 ,  0.5       ]),\n",
       " 'mean_test_f1_macro': array([ 0.14696605,  0.25788617,  0.1597532 ,  0.17894728,  0.17842464,\n",
       "         0.20014762,  0.19011926,  0.17843755,  0.21739003,  0.20338656,\n",
       "         0.15548349,  0.27633304,  0.1804827 ,  0.21497931,  0.19473744,\n",
       "         0.22045919,  0.28670138,  0.21919983,  0.19587057,  0.26554426,\n",
       "         0.16711924,  0.26037172,  0.18975284,  0.28336996,  0.18272999,\n",
       "         0.19981017,  0.22237101,  0.17308626,  0.19605031,  0.2356553 ,\n",
       "         0.22150079,  0.16995631,  0.16093613,  0.19610381,  0.16726256,\n",
       "         0.15561517,  0.17828054,  0.15416081,  0.21525363,  0.17724706,\n",
       "         0.18599832,  0.21488241,  0.14500958,  0.18387122,  0.14845344,\n",
       "         0.21239499,  0.20762728,  0.1718051 ,  0.22864783,  0.20623386,\n",
       "         0.17262594,  0.19495393,  0.15719342,  0.27792659,  0.1469906 ,\n",
       "         0.25045823,  0.17260095,  0.16938765,  0.16720091,  0.22632546,\n",
       "         0.21244587,  0.22989042,  0.27210485,  0.15830892]),\n",
       " 'mean_test_f1_micro': array([ 0.28358209,  0.38059701,  0.32089552,  0.3358209 ,  0.36567164,\n",
       "         0.36567164,  0.35074627,  0.36567164,  0.38059701,  0.36567164,\n",
       "         0.30597015,  0.41044776,  0.34328358,  0.38059701,  0.34328358,\n",
       "         0.38059701,  0.42537313,  0.36567164,  0.28358209,  0.41044776,\n",
       "         0.3358209 ,  0.3880597 ,  0.35074627,  0.41791045,  0.32835821,\n",
       "         0.35820896,  0.35820896,  0.35074627,  0.3358209 ,  0.3880597 ,\n",
       "         0.35074627,  0.34328358,  0.32089552,  0.35820896,  0.3358209 ,\n",
       "         0.30597015,  0.36567164,  0.29850746,  0.3358209 ,  0.3358209 ,\n",
       "         0.35074627,  0.35074627,  0.23880597,  0.31343284,  0.29104478,\n",
       "         0.35074627,  0.37313433,  0.31343284,  0.38059701,  0.36567164,\n",
       "         0.30597015,  0.35074627,  0.31343284,  0.41791045,  0.28358209,\n",
       "         0.39552239,  0.35074627,  0.31343284,  0.29850746,  0.34328358,\n",
       "         0.35820896,  0.3880597 ,  0.38059701,  0.31343284]),\n",
       " 'mean_test_precision_macro': array([ 0.09452736,  0.21669127,  0.10826303,  0.12686567,  0.12189055,\n",
       "         0.14626866,  0.14195688,  0.12189055,  0.18038431,  0.18345771,\n",
       "         0.10199005,  0.2887636 ,  0.18006123,  0.15851048,  0.17599502,\n",
       "         0.18103324,  0.24569017,  0.16514155,  0.20292289,  0.22021234,\n",
       "         0.1119403 ,  0.24275903,  0.15898767,  0.22021917,  0.17303483,\n",
       "         0.14427861,  0.18518242,  0.11691542,  0.14514925,  0.2110827 ,\n",
       "         0.17761194,  0.11532338,  0.10756219,  0.14978678,  0.1119403 ,\n",
       "         0.10199005,  0.12268657,  0.1083511 ,  0.1934507 ,  0.12927212,\n",
       "         0.13890691,  0.19886528,  0.12196229,  0.1918038 ,  0.10281924,\n",
       "         0.18263418,  0.19292002,  0.12919377,  0.17750533,  0.16028623,\n",
       "         0.12898211,  0.14216418,  0.10628675,  0.27819527,  0.09597844,\n",
       "         0.21667427,  0.11691542,  0.12537313,  0.12064677,  0.18756416,\n",
       "         0.16676025,  0.16915423,  0.22566756,  0.10447761]),\n",
       " 'mean_test_precision_micro': array([ 0.28358209,  0.38059701,  0.32089552,  0.3358209 ,  0.36567164,\n",
       "         0.36567164,  0.35074627,  0.36567164,  0.38059701,  0.36567164,\n",
       "         0.30597015,  0.41044776,  0.34328358,  0.38059701,  0.34328358,\n",
       "         0.38059701,  0.42537313,  0.36567164,  0.28358209,  0.41044776,\n",
       "         0.3358209 ,  0.3880597 ,  0.35074627,  0.41791045,  0.32835821,\n",
       "         0.35820896,  0.35820896,  0.35074627,  0.3358209 ,  0.3880597 ,\n",
       "         0.35074627,  0.34328358,  0.32089552,  0.35820896,  0.3358209 ,\n",
       "         0.30597015,  0.36567164,  0.29850746,  0.3358209 ,  0.3358209 ,\n",
       "         0.35074627,  0.35074627,  0.23880597,  0.31343284,  0.29104478,\n",
       "         0.35074627,  0.37313433,  0.31343284,  0.38059701,  0.36567164,\n",
       "         0.30597015,  0.35074627,  0.31343284,  0.41791045,  0.28358209,\n",
       "         0.39552239,  0.35074627,  0.31343284,  0.29850746,  0.34328358,\n",
       "         0.35820896,  0.3880597 ,  0.38059701,  0.31343284]),\n",
       " 'param_classify': masked_array(data = [ MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "        beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "        hidden_layer_sizes=(3,), learning_rate='constant',\n",
       "        learning_rate_init=0.001, max_iter=100000, momentum=0.2,\n",
       "        nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "        shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "        verbose=False, warm_start=False)\n",
       "  MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "        beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "        hidden_layer_sizes=(3,), learning_rate='constant',\n",
       "        learning_rate_init=0.001, max_iter=100000, momentum=0.2,\n",
       "        nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "        shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "        verbose=False, warm_start=False)\n",
       "  MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "        beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "        hidden_layer_sizes=(3,), learning_rate='constant',\n",
       "        learning_rate_init=0.001, max_iter=100000, momentum=0.2,\n",
       "        nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "        shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "        verbose=False, warm_start=False)\n",
       "  MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "        beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "        hidden_layer_sizes=(3,), learning_rate='constant',\n",
       "        learning_rate_init=0.001, max_iter=100000, momentum=0.2,\n",
       "        nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "        shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "        verbose=False, warm_start=False)\n",
       "  MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "        beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "        hidden_layer_sizes=(3,), learning_rate='constant',\n",
       "        learning_rate_init=0.001, max_iter=100000, momentum=0.2,\n",
       "        nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "        shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "        verbose=False, warm_start=False)\n",
       "  MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "        beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "        hidden_layer_sizes=(3,), learning_rate='constant',\n",
       "        learning_rate_init=0.001, max_iter=100000, momentum=0.2,\n",
       "        nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "        shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "        verbose=False, warm_start=False)\n",
       "  MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "        beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "        hidden_layer_sizes=(3,), learning_rate='constant',\n",
       "        learning_rate_init=0.001, max_iter=100000, momentum=0.2,\n",
       "        nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "        shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "        verbose=False, warm_start=False)\n",
       "  MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "        beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "        hidden_layer_sizes=(3,), learning_rate='constant',\n",
       "        learning_rate_init=0.001, max_iter=100000, momentum=0.2,\n",
       "        nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "        shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "        verbose=False, warm_start=False)\n",
       "  MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "        beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "        hidden_layer_sizes=(3,), learning_rate='constant',\n",
       "        learning_rate_init=0.001, max_iter=100000, momentum=0.2,\n",
       "        nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "        shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "        verbose=False, warm_start=False)\n",
       "  MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "        beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "        hidden_layer_sizes=(3,), learning_rate='constant',\n",
       "        learning_rate_init=0.001, max_iter=100000, momentum=0.2,\n",
       "        nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "        shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "        verbose=False, warm_start=False)\n",
       "  MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "        beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "        hidden_layer_sizes=(3,), learning_rate='constant',\n",
       "        learning_rate_init=0.001, max_iter=100000, momentum=0.2,\n",
       "        nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "        shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "        verbose=False, warm_start=False)\n",
       "  MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "        beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "        hidden_layer_sizes=(3,), learning_rate='constant',\n",
       "        learning_rate_init=0.001, max_iter=100000, momentum=0.2,\n",
       "        nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "        shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "        verbose=False, warm_start=False)\n",
       "  MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "        beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "        hidden_layer_sizes=(3,), learning_rate='constant',\n",
       "        learning_rate_init=0.001, max_iter=100000, momentum=0.2,\n",
       "        nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "        shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "        verbose=False, warm_start=False)\n",
       "  MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "        beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "        hidden_layer_sizes=(3,), learning_rate='constant',\n",
       "        learning_rate_init=0.001, max_iter=100000, momentum=0.2,\n",
       "        nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "        shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "        verbose=False, warm_start=False)\n",
       "  MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "        beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "        hidden_layer_sizes=(3,), learning_rate='constant',\n",
       "        learning_rate_init=0.001, max_iter=100000, momentum=0.2,\n",
       "        nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "        shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "        verbose=False, warm_start=False)\n",
       "  MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "        beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "        hidden_layer_sizes=(3,), learning_rate='constant',\n",
       "        learning_rate_init=0.001, max_iter=100000, momentum=0.2,\n",
       "        nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "        shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "        verbose=False, warm_start=False)\n",
       "  MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "        beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "        hidden_layer_sizes=(3,), learning_rate='constant',\n",
       "        learning_rate_init=0.001, max_iter=100000, momentum=0.2,\n",
       "        nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "        shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "        verbose=False, warm_start=False)\n",
       "  MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "        beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "        hidden_layer_sizes=(3,), learning_rate='constant',\n",
       "        learning_rate_init=0.001, max_iter=100000, momentum=0.2,\n",
       "        nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "        shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "        verbose=False, warm_start=False)\n",
       "  MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "        beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "        hidden_layer_sizes=(3,), learning_rate='constant',\n",
       "        learning_rate_init=0.001, max_iter=100000, momentum=0.2,\n",
       "        nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "        shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "        verbose=False, warm_start=False)\n",
       "  MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "        beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "        hidden_layer_sizes=(3,), learning_rate='constant',\n",
       "        learning_rate_init=0.001, max_iter=100000, momentum=0.2,\n",
       "        nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "        shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "        verbose=False, warm_start=False)\n",
       "  MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "        beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "        hidden_layer_sizes=(3,), learning_rate='constant',\n",
       "        learning_rate_init=0.001, max_iter=100000, momentum=0.2,\n",
       "        nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "        shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "        verbose=False, warm_start=False)\n",
       "  MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "        beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "        hidden_layer_sizes=(3,), learning_rate='constant',\n",
       "        learning_rate_init=0.001, max_iter=100000, momentum=0.2,\n",
       "        nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "        shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "        verbose=False, warm_start=False)\n",
       "  MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "        beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "        hidden_layer_sizes=(3,), learning_rate='constant',\n",
       "        learning_rate_init=0.001, max_iter=100000, momentum=0.2,\n",
       "        nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "        shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "        verbose=False, warm_start=False)\n",
       "  MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "        beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "        hidden_layer_sizes=(3,), learning_rate='constant',\n",
       "        learning_rate_init=0.001, max_iter=100000, momentum=0.2,\n",
       "        nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "        shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "        verbose=False, warm_start=False)\n",
       "  MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "        beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "        hidden_layer_sizes=(3,), learning_rate='constant',\n",
       "        learning_rate_init=0.001, max_iter=100000, momentum=0.2,\n",
       "        nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "        shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "        verbose=False, warm_start=False)\n",
       "  MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "        beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "        hidden_layer_sizes=(3,), learning_rate='constant',\n",
       "        learning_rate_init=0.001, max_iter=100000, momentum=0.2,\n",
       "        nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "        shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "        verbose=False, warm_start=False)\n",
       "  MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "        beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "        hidden_layer_sizes=(3,), learning_rate='constant',\n",
       "        learning_rate_init=0.001, max_iter=100000, momentum=0.2,\n",
       "        nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "        shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "        verbose=False, warm_start=False)\n",
       "  MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "        beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "        hidden_layer_sizes=(3,), learning_rate='constant',\n",
       "        learning_rate_init=0.001, max_iter=100000, momentum=0.2,\n",
       "        nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "        shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "        verbose=False, warm_start=False)\n",
       "  MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "        beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "        hidden_layer_sizes=(3,), learning_rate='constant',\n",
       "        learning_rate_init=0.001, max_iter=100000, momentum=0.2,\n",
       "        nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "        shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "        verbose=False, warm_start=False)\n",
       "  MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "        beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "        hidden_layer_sizes=(3,), learning_rate='constant',\n",
       "        learning_rate_init=0.001, max_iter=100000, momentum=0.2,\n",
       "        nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "        shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "        verbose=False, warm_start=False)\n",
       "  MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "        beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "        hidden_layer_sizes=(3,), learning_rate='constant',\n",
       "        learning_rate_init=0.001, max_iter=100000, momentum=0.2,\n",
       "        nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "        shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "        verbose=False, warm_start=False)\n",
       "  MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "        beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "        hidden_layer_sizes=(3,), learning_rate='constant',\n",
       "        learning_rate_init=0.001, max_iter=100000, momentum=0.2,\n",
       "        nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "        shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "        verbose=False, warm_start=False)\n",
       "  MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "        beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "        hidden_layer_sizes=(3,), learning_rate='constant',\n",
       "        learning_rate_init=0.001, max_iter=100000, momentum=0.2,\n",
       "        nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "        shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "        verbose=False, warm_start=False)\n",
       "  MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "        beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "        hidden_layer_sizes=(3,), learning_rate='constant',\n",
       "        learning_rate_init=0.001, max_iter=100000, momentum=0.2,\n",
       "        nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "        shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "        verbose=False, warm_start=False)\n",
       "  MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "        beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "        hidden_layer_sizes=(3,), learning_rate='constant',\n",
       "        learning_rate_init=0.001, max_iter=100000, momentum=0.2,\n",
       "        nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "        shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "        verbose=False, warm_start=False)\n",
       "  MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "        beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "        hidden_layer_sizes=(3,), learning_rate='constant',\n",
       "        learning_rate_init=0.001, max_iter=100000, momentum=0.2,\n",
       "        nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "        shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "        verbose=False, warm_start=False)\n",
       "  MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "        beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "        hidden_layer_sizes=(3,), learning_rate='constant',\n",
       "        learning_rate_init=0.001, max_iter=100000, momentum=0.2,\n",
       "        nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "        shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "        verbose=False, warm_start=False)\n",
       "  MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "        beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "        hidden_layer_sizes=(3,), learning_rate='constant',\n",
       "        learning_rate_init=0.001, max_iter=100000, momentum=0.2,\n",
       "        nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "        shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "        verbose=False, warm_start=False)\n",
       "  MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "        beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "        hidden_layer_sizes=(3,), learning_rate='constant',\n",
       "        learning_rate_init=0.001, max_iter=100000, momentum=0.2,\n",
       "        nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "        shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "        verbose=False, warm_start=False)\n",
       "  MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "        beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "        hidden_layer_sizes=(3,), learning_rate='constant',\n",
       "        learning_rate_init=0.001, max_iter=100000, momentum=0.2,\n",
       "        nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "        shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "        verbose=False, warm_start=False)\n",
       "  MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "        beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "        hidden_layer_sizes=(3,), learning_rate='constant',\n",
       "        learning_rate_init=0.001, max_iter=100000, momentum=0.2,\n",
       "        nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "        shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "        verbose=False, warm_start=False)\n",
       "  MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "        beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "        hidden_layer_sizes=(3,), learning_rate='constant',\n",
       "        learning_rate_init=0.001, max_iter=100000, momentum=0.2,\n",
       "        nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "        shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "        verbose=False, warm_start=False)\n",
       "  MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "        beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "        hidden_layer_sizes=(3,), learning_rate='constant',\n",
       "        learning_rate_init=0.001, max_iter=100000, momentum=0.2,\n",
       "        nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "        shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "        verbose=False, warm_start=False)\n",
       "  MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "        beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "        hidden_layer_sizes=(3,), learning_rate='constant',\n",
       "        learning_rate_init=0.001, max_iter=100000, momentum=0.2,\n",
       "        nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "        shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "        verbose=False, warm_start=False)\n",
       "  MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "        beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "        hidden_layer_sizes=(3,), learning_rate='constant',\n",
       "        learning_rate_init=0.001, max_iter=100000, momentum=0.2,\n",
       "        nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "        shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "        verbose=False, warm_start=False)\n",
       "  MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "        beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "        hidden_layer_sizes=(3,), learning_rate='constant',\n",
       "        learning_rate_init=0.001, max_iter=100000, momentum=0.2,\n",
       "        nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "        shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "        verbose=False, warm_start=False)\n",
       "  MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "        beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "        hidden_layer_sizes=(3,), learning_rate='constant',\n",
       "        learning_rate_init=0.001, max_iter=100000, momentum=0.2,\n",
       "        nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "        shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "        verbose=False, warm_start=False)\n",
       "  MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "        beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "        hidden_layer_sizes=(3,), learning_rate='constant',\n",
       "        learning_rate_init=0.001, max_iter=100000, momentum=0.2,\n",
       "        nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "        shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "        verbose=False, warm_start=False)\n",
       "  MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "        beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "        hidden_layer_sizes=(3,), learning_rate='constant',\n",
       "        learning_rate_init=0.001, max_iter=100000, momentum=0.2,\n",
       "        nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "        shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "        verbose=False, warm_start=False)\n",
       "  MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "        beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "        hidden_layer_sizes=(3,), learning_rate='constant',\n",
       "        learning_rate_init=0.001, max_iter=100000, momentum=0.2,\n",
       "        nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "        shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "        verbose=False, warm_start=False)\n",
       "  MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "        beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "        hidden_layer_sizes=(3,), learning_rate='constant',\n",
       "        learning_rate_init=0.001, max_iter=100000, momentum=0.2,\n",
       "        nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "        shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "        verbose=False, warm_start=False)\n",
       "  MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "        beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "        hidden_layer_sizes=(3,), learning_rate='constant',\n",
       "        learning_rate_init=0.001, max_iter=100000, momentum=0.2,\n",
       "        nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "        shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "        verbose=False, warm_start=False)\n",
       "  MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "        beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "        hidden_layer_sizes=(3,), learning_rate='constant',\n",
       "        learning_rate_init=0.001, max_iter=100000, momentum=0.2,\n",
       "        nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "        shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "        verbose=False, warm_start=False)\n",
       "  MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "        beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "        hidden_layer_sizes=(3,), learning_rate='constant',\n",
       "        learning_rate_init=0.001, max_iter=100000, momentum=0.2,\n",
       "        nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "        shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "        verbose=False, warm_start=False)\n",
       "  MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "        beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "        hidden_layer_sizes=(3,), learning_rate='constant',\n",
       "        learning_rate_init=0.001, max_iter=100000, momentum=0.2,\n",
       "        nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "        shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "        verbose=False, warm_start=False)\n",
       "  MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "        beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "        hidden_layer_sizes=(3,), learning_rate='constant',\n",
       "        learning_rate_init=0.001, max_iter=100000, momentum=0.2,\n",
       "        nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "        shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "        verbose=False, warm_start=False)\n",
       "  MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "        beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "        hidden_layer_sizes=(3,), learning_rate='constant',\n",
       "        learning_rate_init=0.001, max_iter=100000, momentum=0.2,\n",
       "        nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "        shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "        verbose=False, warm_start=False)\n",
       "  MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "        beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "        hidden_layer_sizes=(3,), learning_rate='constant',\n",
       "        learning_rate_init=0.001, max_iter=100000, momentum=0.2,\n",
       "        nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "        shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "        verbose=False, warm_start=False)\n",
       "  MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "        beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "        hidden_layer_sizes=(3,), learning_rate='constant',\n",
       "        learning_rate_init=0.001, max_iter=100000, momentum=0.2,\n",
       "        nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "        shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "        verbose=False, warm_start=False)\n",
       "  MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "        beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "        hidden_layer_sizes=(3,), learning_rate='constant',\n",
       "        learning_rate_init=0.001, max_iter=100000, momentum=0.2,\n",
       "        nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "        shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "        verbose=False, warm_start=False)\n",
       "  MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "        beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "        hidden_layer_sizes=(3,), learning_rate='constant',\n",
       "        learning_rate_init=0.001, max_iter=100000, momentum=0.2,\n",
       "        nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "        shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "        verbose=False, warm_start=False)\n",
       "  MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "        beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "        hidden_layer_sizes=(3,), learning_rate='constant',\n",
       "        learning_rate_init=0.001, max_iter=100000, momentum=0.2,\n",
       "        nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "        shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "        verbose=False, warm_start=False)\n",
       "  MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "        beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "        hidden_layer_sizes=(3,), learning_rate='constant',\n",
       "        learning_rate_init=0.001, max_iter=100000, momentum=0.2,\n",
       "        nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "        shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "        verbose=False, warm_start=False)\n",
       "  MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "        beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "        hidden_layer_sizes=(3,), learning_rate='constant',\n",
       "        learning_rate_init=0.001, max_iter=100000, momentum=0.2,\n",
       "        nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "        shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "        verbose=False, warm_start=False)],\n",
       "              mask = [False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False],\n",
       "        fill_value = ?),\n",
       " 'param_classify__hidden_layer_sizes': masked_array(data = [(2,) (2,) (2,) (2,) (2,) (2,) (2,) (2,) (2,) (2,) (2,) (2,) (2,) (2,) (2,)\n",
       "  (2,) (3,) (3,) (3,) (3,) (3,) (3,) (3,) (3,) (3,) (3,) (3,) (3,) (3,) (3,)\n",
       "  (3,) (3,) (3,) (3,) (3,) (3,) (3,) (3,) (3,) (3,) (3,) (3,) (3,) (3,) (3,)\n",
       "  (3,) (3,) (3,) (6,) (6,) (6,) (6,) (6,) (6,) (6,) (6,) (6,) (6,) (6,) (6,)\n",
       "  (6,) (6,) (6,) (6,)],\n",
       "              mask = [False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False],\n",
       "        fill_value = ?),\n",
       " 'param_classify__learning_rate': masked_array(data = ['constant' 'constant' 'constant' 'constant' 'constant' 'constant'\n",
       "  'constant' 'constant' 'constant' 'constant' 'constant' 'constant'\n",
       "  'constant' 'constant' 'constant' 'constant' 'constant' 'constant'\n",
       "  'constant' 'constant' 'constant' 'constant' 'constant' 'constant'\n",
       "  'constant' 'constant' 'constant' 'constant' 'constant' 'constant'\n",
       "  'constant' 'constant' 'constant' 'constant' 'constant' 'constant'\n",
       "  'constant' 'constant' 'constant' 'constant' 'constant' 'constant'\n",
       "  'constant' 'constant' 'constant' 'constant' 'constant' 'constant'\n",
       "  'constant' 'constant' 'constant' 'constant' 'constant' 'constant'\n",
       "  'constant' 'constant' 'constant' 'constant' 'constant' 'constant'\n",
       "  'constant' 'constant' 'constant' 'constant'],\n",
       "              mask = [False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False],\n",
       "        fill_value = ?),\n",
       " 'param_classify__max_iter': masked_array(data = [100000 100000 100000 100000 100000 100000 100000 100000 100000 100000\n",
       "  100000 100000 100000 100000 100000 100000 100000 100000 100000 100000\n",
       "  100000 100000 100000 100000 100000 100000 100000 100000 100000 100000\n",
       "  100000 100000 100000 100000 100000 100000 100000 100000 100000 100000\n",
       "  100000 100000 100000 100000 100000 100000 100000 100000 100000 100000\n",
       "  100000 100000 100000 100000 100000 100000 100000 100000 100000 100000\n",
       "  100000 100000 100000 100000],\n",
       "              mask = [False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False],\n",
       "        fill_value = ?),\n",
       " 'param_classify__momentum': masked_array(data = [0.01 0.01 0.05 0.05 0.1 0.1 0.2 0.2 0.4 0.4 0.6 0.6 0.8 0.8 0.9 0.9 0.01\n",
       "  0.01 0.05 0.05 0.1 0.1 0.2 0.2 0.4 0.4 0.6 0.6 0.8 0.8 0.9 0.9 0.01 0.01\n",
       "  0.05 0.05 0.1 0.1 0.2 0.2 0.4 0.4 0.6 0.6 0.8 0.8 0.9 0.9 0.01 0.01 0.05\n",
       "  0.05 0.1 0.1 0.2 0.2 0.4 0.4 0.6 0.6 0.8 0.8 0.9 0.9],\n",
       "              mask = [False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False],\n",
       "        fill_value = ?),\n",
       " 'param_reduce_dim': masked_array(data = [SelectKBest(k=10, score_func=<function f_classif at 0x118c10510>)\n",
       "  SelectKBest(k=5, score_func=<function mutual_info_classif at 0x118d43158>)\n",
       "  SelectKBest(k=10, score_func=<function f_classif at 0x118c10510>)\n",
       "  SelectKBest(k=5, score_func=<function mutual_info_classif at 0x118d43158>)\n",
       "  SelectKBest(k=10, score_func=<function f_classif at 0x118c10510>)\n",
       "  SelectKBest(k=5, score_func=<function mutual_info_classif at 0x118d43158>)\n",
       "  SelectKBest(k=10, score_func=<function f_classif at 0x118c10510>)\n",
       "  SelectKBest(k=5, score_func=<function mutual_info_classif at 0x118d43158>)\n",
       "  SelectKBest(k=10, score_func=<function f_classif at 0x118c10510>)\n",
       "  SelectKBest(k=5, score_func=<function mutual_info_classif at 0x118d43158>)\n",
       "  SelectKBest(k=10, score_func=<function f_classif at 0x118c10510>)\n",
       "  SelectKBest(k=5, score_func=<function mutual_info_classif at 0x118d43158>)\n",
       "  SelectKBest(k=10, score_func=<function f_classif at 0x118c10510>)\n",
       "  SelectKBest(k=5, score_func=<function mutual_info_classif at 0x118d43158>)\n",
       "  SelectKBest(k=10, score_func=<function f_classif at 0x118c10510>)\n",
       "  SelectKBest(k=5, score_func=<function mutual_info_classif at 0x118d43158>)\n",
       "  SelectKBest(k=10, score_func=<function f_classif at 0x118c10510>)\n",
       "  SelectKBest(k=5, score_func=<function mutual_info_classif at 0x118d43158>)\n",
       "  SelectKBest(k=10, score_func=<function f_classif at 0x118c10510>)\n",
       "  SelectKBest(k=5, score_func=<function mutual_info_classif at 0x118d43158>)\n",
       "  SelectKBest(k=10, score_func=<function f_classif at 0x118c10510>)\n",
       "  SelectKBest(k=5, score_func=<function mutual_info_classif at 0x118d43158>)\n",
       "  SelectKBest(k=10, score_func=<function f_classif at 0x118c10510>)\n",
       "  SelectKBest(k=5, score_func=<function mutual_info_classif at 0x118d43158>)\n",
       "  SelectKBest(k=10, score_func=<function f_classif at 0x118c10510>)\n",
       "  SelectKBest(k=5, score_func=<function mutual_info_classif at 0x118d43158>)\n",
       "  SelectKBest(k=10, score_func=<function f_classif at 0x118c10510>)\n",
       "  SelectKBest(k=5, score_func=<function mutual_info_classif at 0x118d43158>)\n",
       "  SelectKBest(k=10, score_func=<function f_classif at 0x118c10510>)\n",
       "  SelectKBest(k=5, score_func=<function mutual_info_classif at 0x118d43158>)\n",
       "  SelectKBest(k=10, score_func=<function f_classif at 0x118c10510>)\n",
       "  SelectKBest(k=5, score_func=<function mutual_info_classif at 0x118d43158>)\n",
       "  SelectKBest(k=10, score_func=<function f_classif at 0x118c10510>)\n",
       "  SelectKBest(k=5, score_func=<function mutual_info_classif at 0x118d43158>)\n",
       "  SelectKBest(k=10, score_func=<function f_classif at 0x118c10510>)\n",
       "  SelectKBest(k=5, score_func=<function mutual_info_classif at 0x118d43158>)\n",
       "  SelectKBest(k=10, score_func=<function f_classif at 0x118c10510>)\n",
       "  SelectKBest(k=5, score_func=<function mutual_info_classif at 0x118d43158>)\n",
       "  SelectKBest(k=10, score_func=<function f_classif at 0x118c10510>)\n",
       "  SelectKBest(k=5, score_func=<function mutual_info_classif at 0x118d43158>)\n",
       "  SelectKBest(k=10, score_func=<function f_classif at 0x118c10510>)\n",
       "  SelectKBest(k=5, score_func=<function mutual_info_classif at 0x118d43158>)\n",
       "  SelectKBest(k=10, score_func=<function f_classif at 0x118c10510>)\n",
       "  SelectKBest(k=5, score_func=<function mutual_info_classif at 0x118d43158>)\n",
       "  SelectKBest(k=10, score_func=<function f_classif at 0x118c10510>)\n",
       "  SelectKBest(k=5, score_func=<function mutual_info_classif at 0x118d43158>)\n",
       "  SelectKBest(k=10, score_func=<function f_classif at 0x118c10510>)\n",
       "  SelectKBest(k=5, score_func=<function mutual_info_classif at 0x118d43158>)\n",
       "  SelectKBest(k=10, score_func=<function f_classif at 0x118c10510>)\n",
       "  SelectKBest(k=5, score_func=<function mutual_info_classif at 0x118d43158>)\n",
       "  SelectKBest(k=10, score_func=<function f_classif at 0x118c10510>)\n",
       "  SelectKBest(k=5, score_func=<function mutual_info_classif at 0x118d43158>)\n",
       "  SelectKBest(k=10, score_func=<function f_classif at 0x118c10510>)\n",
       "  SelectKBest(k=5, score_func=<function mutual_info_classif at 0x118d43158>)\n",
       "  SelectKBest(k=10, score_func=<function f_classif at 0x118c10510>)\n",
       "  SelectKBest(k=5, score_func=<function mutual_info_classif at 0x118d43158>)\n",
       "  SelectKBest(k=10, score_func=<function f_classif at 0x118c10510>)\n",
       "  SelectKBest(k=5, score_func=<function mutual_info_classif at 0x118d43158>)\n",
       "  SelectKBest(k=10, score_func=<function f_classif at 0x118c10510>)\n",
       "  SelectKBest(k=5, score_func=<function mutual_info_classif at 0x118d43158>)\n",
       "  SelectKBest(k=10, score_func=<function f_classif at 0x118c10510>)\n",
       "  SelectKBest(k=5, score_func=<function mutual_info_classif at 0x118d43158>)\n",
       "  SelectKBest(k=10, score_func=<function f_classif at 0x118c10510>)\n",
       "  SelectKBest(k=5, score_func=<function mutual_info_classif at 0x118d43158>)],\n",
       "              mask = [False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False],\n",
       "        fill_value = ?),\n",
       " 'param_reduce_dim__k': masked_array(data = [5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 10 10 10\n",
       "  10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n",
       "  10 10 10 10],\n",
       "              mask = [False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False],\n",
       "        fill_value = ?),\n",
       " 'params': [{'classify': MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "          beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "          hidden_layer_sizes=(3,), learning_rate='constant',\n",
       "          learning_rate_init=0.001, max_iter=100000, momentum=0.2,\n",
       "          nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "          shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "          verbose=False, warm_start=False),\n",
       "   'classify__hidden_layer_sizes': (2,),\n",
       "   'classify__learning_rate': 'constant',\n",
       "   'classify__max_iter': 100000,\n",
       "   'classify__momentum': 0.01,\n",
       "   'reduce_dim': SelectKBest(k=10, score_func=<function f_classif at 0x118c10510>),\n",
       "   'reduce_dim__k': 5},\n",
       "  {'classify': MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "          beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "          hidden_layer_sizes=(3,), learning_rate='constant',\n",
       "          learning_rate_init=0.001, max_iter=100000, momentum=0.2,\n",
       "          nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "          shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "          verbose=False, warm_start=False),\n",
       "   'classify__hidden_layer_sizes': (2,),\n",
       "   'classify__learning_rate': 'constant',\n",
       "   'classify__max_iter': 100000,\n",
       "   'classify__momentum': 0.01,\n",
       "   'reduce_dim': SelectKBest(k=5, score_func=<function mutual_info_classif at 0x118d43158>),\n",
       "   'reduce_dim__k': 5},\n",
       "  {'classify': MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "          beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "          hidden_layer_sizes=(3,), learning_rate='constant',\n",
       "          learning_rate_init=0.001, max_iter=100000, momentum=0.2,\n",
       "          nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "          shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "          verbose=False, warm_start=False),\n",
       "   'classify__hidden_layer_sizes': (2,),\n",
       "   'classify__learning_rate': 'constant',\n",
       "   'classify__max_iter': 100000,\n",
       "   'classify__momentum': 0.05,\n",
       "   'reduce_dim': SelectKBest(k=10, score_func=<function f_classif at 0x118c10510>),\n",
       "   'reduce_dim__k': 5},\n",
       "  {'classify': MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "          beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "          hidden_layer_sizes=(3,), learning_rate='constant',\n",
       "          learning_rate_init=0.001, max_iter=100000, momentum=0.2,\n",
       "          nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "          shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "          verbose=False, warm_start=False),\n",
       "   'classify__hidden_layer_sizes': (2,),\n",
       "   'classify__learning_rate': 'constant',\n",
       "   'classify__max_iter': 100000,\n",
       "   'classify__momentum': 0.05,\n",
       "   'reduce_dim': SelectKBest(k=5, score_func=<function mutual_info_classif at 0x118d43158>),\n",
       "   'reduce_dim__k': 5},\n",
       "  {'classify': MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "          beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "          hidden_layer_sizes=(3,), learning_rate='constant',\n",
       "          learning_rate_init=0.001, max_iter=100000, momentum=0.2,\n",
       "          nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "          shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "          verbose=False, warm_start=False),\n",
       "   'classify__hidden_layer_sizes': (2,),\n",
       "   'classify__learning_rate': 'constant',\n",
       "   'classify__max_iter': 100000,\n",
       "   'classify__momentum': 0.1,\n",
       "   'reduce_dim': SelectKBest(k=10, score_func=<function f_classif at 0x118c10510>),\n",
       "   'reduce_dim__k': 5},\n",
       "  {'classify': MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "          beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "          hidden_layer_sizes=(3,), learning_rate='constant',\n",
       "          learning_rate_init=0.001, max_iter=100000, momentum=0.2,\n",
       "          nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "          shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "          verbose=False, warm_start=False),\n",
       "   'classify__hidden_layer_sizes': (2,),\n",
       "   'classify__learning_rate': 'constant',\n",
       "   'classify__max_iter': 100000,\n",
       "   'classify__momentum': 0.1,\n",
       "   'reduce_dim': SelectKBest(k=5, score_func=<function mutual_info_classif at 0x118d43158>),\n",
       "   'reduce_dim__k': 5},\n",
       "  {'classify': MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "          beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "          hidden_layer_sizes=(3,), learning_rate='constant',\n",
       "          learning_rate_init=0.001, max_iter=100000, momentum=0.2,\n",
       "          nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "          shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "          verbose=False, warm_start=False),\n",
       "   'classify__hidden_layer_sizes': (2,),\n",
       "   'classify__learning_rate': 'constant',\n",
       "   'classify__max_iter': 100000,\n",
       "   'classify__momentum': 0.2,\n",
       "   'reduce_dim': SelectKBest(k=10, score_func=<function f_classif at 0x118c10510>),\n",
       "   'reduce_dim__k': 5},\n",
       "  {'classify': MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "          beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "          hidden_layer_sizes=(3,), learning_rate='constant',\n",
       "          learning_rate_init=0.001, max_iter=100000, momentum=0.2,\n",
       "          nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "          shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "          verbose=False, warm_start=False),\n",
       "   'classify__hidden_layer_sizes': (2,),\n",
       "   'classify__learning_rate': 'constant',\n",
       "   'classify__max_iter': 100000,\n",
       "   'classify__momentum': 0.2,\n",
       "   'reduce_dim': SelectKBest(k=5, score_func=<function mutual_info_classif at 0x118d43158>),\n",
       "   'reduce_dim__k': 5},\n",
       "  {'classify': MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "          beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "          hidden_layer_sizes=(3,), learning_rate='constant',\n",
       "          learning_rate_init=0.001, max_iter=100000, momentum=0.2,\n",
       "          nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "          shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "          verbose=False, warm_start=False),\n",
       "   'classify__hidden_layer_sizes': (2,),\n",
       "   'classify__learning_rate': 'constant',\n",
       "   'classify__max_iter': 100000,\n",
       "   'classify__momentum': 0.4,\n",
       "   'reduce_dim': SelectKBest(k=10, score_func=<function f_classif at 0x118c10510>),\n",
       "   'reduce_dim__k': 5},\n",
       "  {'classify': MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "          beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "          hidden_layer_sizes=(3,), learning_rate='constant',\n",
       "          learning_rate_init=0.001, max_iter=100000, momentum=0.2,\n",
       "          nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "          shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "          verbose=False, warm_start=False),\n",
       "   'classify__hidden_layer_sizes': (2,),\n",
       "   'classify__learning_rate': 'constant',\n",
       "   'classify__max_iter': 100000,\n",
       "   'classify__momentum': 0.4,\n",
       "   'reduce_dim': SelectKBest(k=5, score_func=<function mutual_info_classif at 0x118d43158>),\n",
       "   'reduce_dim__k': 5},\n",
       "  {'classify': MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "          beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "          hidden_layer_sizes=(3,), learning_rate='constant',\n",
       "          learning_rate_init=0.001, max_iter=100000, momentum=0.2,\n",
       "          nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "          shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "          verbose=False, warm_start=False),\n",
       "   'classify__hidden_layer_sizes': (2,),\n",
       "   'classify__learning_rate': 'constant',\n",
       "   'classify__max_iter': 100000,\n",
       "   'classify__momentum': 0.6,\n",
       "   'reduce_dim': SelectKBest(k=10, score_func=<function f_classif at 0x118c10510>),\n",
       "   'reduce_dim__k': 5},\n",
       "  {'classify': MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "          beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "          hidden_layer_sizes=(3,), learning_rate='constant',\n",
       "          learning_rate_init=0.001, max_iter=100000, momentum=0.2,\n",
       "          nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "          shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "          verbose=False, warm_start=False),\n",
       "   'classify__hidden_layer_sizes': (2,),\n",
       "   'classify__learning_rate': 'constant',\n",
       "   'classify__max_iter': 100000,\n",
       "   'classify__momentum': 0.6,\n",
       "   'reduce_dim': SelectKBest(k=5, score_func=<function mutual_info_classif at 0x118d43158>),\n",
       "   'reduce_dim__k': 5},\n",
       "  {'classify': MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "          beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "          hidden_layer_sizes=(3,), learning_rate='constant',\n",
       "          learning_rate_init=0.001, max_iter=100000, momentum=0.2,\n",
       "          nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "          shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "          verbose=False, warm_start=False),\n",
       "   'classify__hidden_layer_sizes': (2,),\n",
       "   'classify__learning_rate': 'constant',\n",
       "   'classify__max_iter': 100000,\n",
       "   'classify__momentum': 0.8,\n",
       "   'reduce_dim': SelectKBest(k=10, score_func=<function f_classif at 0x118c10510>),\n",
       "   'reduce_dim__k': 5},\n",
       "  {'classify': MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "          beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "          hidden_layer_sizes=(3,), learning_rate='constant',\n",
       "          learning_rate_init=0.001, max_iter=100000, momentum=0.2,\n",
       "          nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "          shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "          verbose=False, warm_start=False),\n",
       "   'classify__hidden_layer_sizes': (2,),\n",
       "   'classify__learning_rate': 'constant',\n",
       "   'classify__max_iter': 100000,\n",
       "   'classify__momentum': 0.8,\n",
       "   'reduce_dim': SelectKBest(k=5, score_func=<function mutual_info_classif at 0x118d43158>),\n",
       "   'reduce_dim__k': 5},\n",
       "  {'classify': MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "          beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "          hidden_layer_sizes=(3,), learning_rate='constant',\n",
       "          learning_rate_init=0.001, max_iter=100000, momentum=0.2,\n",
       "          nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "          shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "          verbose=False, warm_start=False),\n",
       "   'classify__hidden_layer_sizes': (2,),\n",
       "   'classify__learning_rate': 'constant',\n",
       "   'classify__max_iter': 100000,\n",
       "   'classify__momentum': 0.9,\n",
       "   'reduce_dim': SelectKBest(k=10, score_func=<function f_classif at 0x118c10510>),\n",
       "   'reduce_dim__k': 5},\n",
       "  {'classify': MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "          beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "          hidden_layer_sizes=(3,), learning_rate='constant',\n",
       "          learning_rate_init=0.001, max_iter=100000, momentum=0.2,\n",
       "          nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "          shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "          verbose=False, warm_start=False),\n",
       "   'classify__hidden_layer_sizes': (2,),\n",
       "   'classify__learning_rate': 'constant',\n",
       "   'classify__max_iter': 100000,\n",
       "   'classify__momentum': 0.9,\n",
       "   'reduce_dim': SelectKBest(k=5, score_func=<function mutual_info_classif at 0x118d43158>),\n",
       "   'reduce_dim__k': 5},\n",
       "  {'classify': MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "          beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "          hidden_layer_sizes=(3,), learning_rate='constant',\n",
       "          learning_rate_init=0.001, max_iter=100000, momentum=0.2,\n",
       "          nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "          shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "          verbose=False, warm_start=False),\n",
       "   'classify__hidden_layer_sizes': (3,),\n",
       "   'classify__learning_rate': 'constant',\n",
       "   'classify__max_iter': 100000,\n",
       "   'classify__momentum': 0.01,\n",
       "   'reduce_dim': SelectKBest(k=10, score_func=<function f_classif at 0x118c10510>),\n",
       "   'reduce_dim__k': 5},\n",
       "  {'classify': MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "          beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "          hidden_layer_sizes=(3,), learning_rate='constant',\n",
       "          learning_rate_init=0.001, max_iter=100000, momentum=0.2,\n",
       "          nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "          shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "          verbose=False, warm_start=False),\n",
       "   'classify__hidden_layer_sizes': (3,),\n",
       "   'classify__learning_rate': 'constant',\n",
       "   'classify__max_iter': 100000,\n",
       "   'classify__momentum': 0.01,\n",
       "   'reduce_dim': SelectKBest(k=5, score_func=<function mutual_info_classif at 0x118d43158>),\n",
       "   'reduce_dim__k': 5},\n",
       "  {'classify': MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "          beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "          hidden_layer_sizes=(3,), learning_rate='constant',\n",
       "          learning_rate_init=0.001, max_iter=100000, momentum=0.2,\n",
       "          nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "          shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "          verbose=False, warm_start=False),\n",
       "   'classify__hidden_layer_sizes': (3,),\n",
       "   'classify__learning_rate': 'constant',\n",
       "   'classify__max_iter': 100000,\n",
       "   'classify__momentum': 0.05,\n",
       "   'reduce_dim': SelectKBest(k=10, score_func=<function f_classif at 0x118c10510>),\n",
       "   'reduce_dim__k': 5},\n",
       "  {'classify': MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "          beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "          hidden_layer_sizes=(3,), learning_rate='constant',\n",
       "          learning_rate_init=0.001, max_iter=100000, momentum=0.2,\n",
       "          nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "          shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "          verbose=False, warm_start=False),\n",
       "   'classify__hidden_layer_sizes': (3,),\n",
       "   'classify__learning_rate': 'constant',\n",
       "   'classify__max_iter': 100000,\n",
       "   'classify__momentum': 0.05,\n",
       "   'reduce_dim': SelectKBest(k=5, score_func=<function mutual_info_classif at 0x118d43158>),\n",
       "   'reduce_dim__k': 5},\n",
       "  {'classify': MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "          beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "          hidden_layer_sizes=(3,), learning_rate='constant',\n",
       "          learning_rate_init=0.001, max_iter=100000, momentum=0.2,\n",
       "          nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "          shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "          verbose=False, warm_start=False),\n",
       "   'classify__hidden_layer_sizes': (3,),\n",
       "   'classify__learning_rate': 'constant',\n",
       "   'classify__max_iter': 100000,\n",
       "   'classify__momentum': 0.1,\n",
       "   'reduce_dim': SelectKBest(k=10, score_func=<function f_classif at 0x118c10510>),\n",
       "   'reduce_dim__k': 5},\n",
       "  {'classify': MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "          beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "          hidden_layer_sizes=(3,), learning_rate='constant',\n",
       "          learning_rate_init=0.001, max_iter=100000, momentum=0.2,\n",
       "          nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "          shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "          verbose=False, warm_start=False),\n",
       "   'classify__hidden_layer_sizes': (3,),\n",
       "   'classify__learning_rate': 'constant',\n",
       "   'classify__max_iter': 100000,\n",
       "   'classify__momentum': 0.1,\n",
       "   'reduce_dim': SelectKBest(k=5, score_func=<function mutual_info_classif at 0x118d43158>),\n",
       "   'reduce_dim__k': 5},\n",
       "  {'classify': MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "          beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "          hidden_layer_sizes=(3,), learning_rate='constant',\n",
       "          learning_rate_init=0.001, max_iter=100000, momentum=0.2,\n",
       "          nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "          shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "          verbose=False, warm_start=False),\n",
       "   'classify__hidden_layer_sizes': (3,),\n",
       "   'classify__learning_rate': 'constant',\n",
       "   'classify__max_iter': 100000,\n",
       "   'classify__momentum': 0.2,\n",
       "   'reduce_dim': SelectKBest(k=10, score_func=<function f_classif at 0x118c10510>),\n",
       "   'reduce_dim__k': 5},\n",
       "  {'classify': MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "          beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "          hidden_layer_sizes=(3,), learning_rate='constant',\n",
       "          learning_rate_init=0.001, max_iter=100000, momentum=0.2,\n",
       "          nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "          shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "          verbose=False, warm_start=False),\n",
       "   'classify__hidden_layer_sizes': (3,),\n",
       "   'classify__learning_rate': 'constant',\n",
       "   'classify__max_iter': 100000,\n",
       "   'classify__momentum': 0.2,\n",
       "   'reduce_dim': SelectKBest(k=5, score_func=<function mutual_info_classif at 0x118d43158>),\n",
       "   'reduce_dim__k': 5},\n",
       "  {'classify': MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "          beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "          hidden_layer_sizes=(3,), learning_rate='constant',\n",
       "          learning_rate_init=0.001, max_iter=100000, momentum=0.2,\n",
       "          nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "          shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "          verbose=False, warm_start=False),\n",
       "   'classify__hidden_layer_sizes': (3,),\n",
       "   'classify__learning_rate': 'constant',\n",
       "   'classify__max_iter': 100000,\n",
       "   'classify__momentum': 0.4,\n",
       "   'reduce_dim': SelectKBest(k=10, score_func=<function f_classif at 0x118c10510>),\n",
       "   'reduce_dim__k': 5},\n",
       "  {'classify': MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "          beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "          hidden_layer_sizes=(3,), learning_rate='constant',\n",
       "          learning_rate_init=0.001, max_iter=100000, momentum=0.2,\n",
       "          nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "          shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "          verbose=False, warm_start=False),\n",
       "   'classify__hidden_layer_sizes': (3,),\n",
       "   'classify__learning_rate': 'constant',\n",
       "   'classify__max_iter': 100000,\n",
       "   'classify__momentum': 0.4,\n",
       "   'reduce_dim': SelectKBest(k=5, score_func=<function mutual_info_classif at 0x118d43158>),\n",
       "   'reduce_dim__k': 5},\n",
       "  {'classify': MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "          beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "          hidden_layer_sizes=(3,), learning_rate='constant',\n",
       "          learning_rate_init=0.001, max_iter=100000, momentum=0.2,\n",
       "          nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "          shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "          verbose=False, warm_start=False),\n",
       "   'classify__hidden_layer_sizes': (3,),\n",
       "   'classify__learning_rate': 'constant',\n",
       "   'classify__max_iter': 100000,\n",
       "   'classify__momentum': 0.6,\n",
       "   'reduce_dim': SelectKBest(k=10, score_func=<function f_classif at 0x118c10510>),\n",
       "   'reduce_dim__k': 5},\n",
       "  {'classify': MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "          beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "          hidden_layer_sizes=(3,), learning_rate='constant',\n",
       "          learning_rate_init=0.001, max_iter=100000, momentum=0.2,\n",
       "          nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "          shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "          verbose=False, warm_start=False),\n",
       "   'classify__hidden_layer_sizes': (3,),\n",
       "   'classify__learning_rate': 'constant',\n",
       "   'classify__max_iter': 100000,\n",
       "   'classify__momentum': 0.6,\n",
       "   'reduce_dim': SelectKBest(k=5, score_func=<function mutual_info_classif at 0x118d43158>),\n",
       "   'reduce_dim__k': 5},\n",
       "  {'classify': MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "          beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "          hidden_layer_sizes=(3,), learning_rate='constant',\n",
       "          learning_rate_init=0.001, max_iter=100000, momentum=0.2,\n",
       "          nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "          shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "          verbose=False, warm_start=False),\n",
       "   'classify__hidden_layer_sizes': (3,),\n",
       "   'classify__learning_rate': 'constant',\n",
       "   'classify__max_iter': 100000,\n",
       "   'classify__momentum': 0.8,\n",
       "   'reduce_dim': SelectKBest(k=10, score_func=<function f_classif at 0x118c10510>),\n",
       "   'reduce_dim__k': 5},\n",
       "  {'classify': MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "          beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "          hidden_layer_sizes=(3,), learning_rate='constant',\n",
       "          learning_rate_init=0.001, max_iter=100000, momentum=0.2,\n",
       "          nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "          shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "          verbose=False, warm_start=False),\n",
       "   'classify__hidden_layer_sizes': (3,),\n",
       "   'classify__learning_rate': 'constant',\n",
       "   'classify__max_iter': 100000,\n",
       "   'classify__momentum': 0.8,\n",
       "   'reduce_dim': SelectKBest(k=5, score_func=<function mutual_info_classif at 0x118d43158>),\n",
       "   'reduce_dim__k': 5},\n",
       "  {'classify': MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "          beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "          hidden_layer_sizes=(3,), learning_rate='constant',\n",
       "          learning_rate_init=0.001, max_iter=100000, momentum=0.2,\n",
       "          nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "          shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "          verbose=False, warm_start=False),\n",
       "   'classify__hidden_layer_sizes': (3,),\n",
       "   'classify__learning_rate': 'constant',\n",
       "   'classify__max_iter': 100000,\n",
       "   'classify__momentum': 0.9,\n",
       "   'reduce_dim': SelectKBest(k=10, score_func=<function f_classif at 0x118c10510>),\n",
       "   'reduce_dim__k': 5},\n",
       "  {'classify': MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "          beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "          hidden_layer_sizes=(3,), learning_rate='constant',\n",
       "          learning_rate_init=0.001, max_iter=100000, momentum=0.2,\n",
       "          nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "          shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "          verbose=False, warm_start=False),\n",
       "   'classify__hidden_layer_sizes': (3,),\n",
       "   'classify__learning_rate': 'constant',\n",
       "   'classify__max_iter': 100000,\n",
       "   'classify__momentum': 0.9,\n",
       "   'reduce_dim': SelectKBest(k=5, score_func=<function mutual_info_classif at 0x118d43158>),\n",
       "   'reduce_dim__k': 5},\n",
       "  {'classify': MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "          beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "          hidden_layer_sizes=(3,), learning_rate='constant',\n",
       "          learning_rate_init=0.001, max_iter=100000, momentum=0.2,\n",
       "          nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "          shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "          verbose=False, warm_start=False),\n",
       "   'classify__hidden_layer_sizes': (3,),\n",
       "   'classify__learning_rate': 'constant',\n",
       "   'classify__max_iter': 100000,\n",
       "   'classify__momentum': 0.01,\n",
       "   'reduce_dim': SelectKBest(k=10, score_func=<function f_classif at 0x118c10510>),\n",
       "   'reduce_dim__k': 10},\n",
       "  {'classify': MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "          beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "          hidden_layer_sizes=(3,), learning_rate='constant',\n",
       "          learning_rate_init=0.001, max_iter=100000, momentum=0.2,\n",
       "          nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "          shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "          verbose=False, warm_start=False),\n",
       "   'classify__hidden_layer_sizes': (3,),\n",
       "   'classify__learning_rate': 'constant',\n",
       "   'classify__max_iter': 100000,\n",
       "   'classify__momentum': 0.01,\n",
       "   'reduce_dim': SelectKBest(k=5, score_func=<function mutual_info_classif at 0x118d43158>),\n",
       "   'reduce_dim__k': 10},\n",
       "  {'classify': MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "          beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "          hidden_layer_sizes=(3,), learning_rate='constant',\n",
       "          learning_rate_init=0.001, max_iter=100000, momentum=0.2,\n",
       "          nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "          shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "          verbose=False, warm_start=False),\n",
       "   'classify__hidden_layer_sizes': (3,),\n",
       "   'classify__learning_rate': 'constant',\n",
       "   'classify__max_iter': 100000,\n",
       "   'classify__momentum': 0.05,\n",
       "   'reduce_dim': SelectKBest(k=10, score_func=<function f_classif at 0x118c10510>),\n",
       "   'reduce_dim__k': 10},\n",
       "  {'classify': MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "          beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "          hidden_layer_sizes=(3,), learning_rate='constant',\n",
       "          learning_rate_init=0.001, max_iter=100000, momentum=0.2,\n",
       "          nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "          shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "          verbose=False, warm_start=False),\n",
       "   'classify__hidden_layer_sizes': (3,),\n",
       "   'classify__learning_rate': 'constant',\n",
       "   'classify__max_iter': 100000,\n",
       "   'classify__momentum': 0.05,\n",
       "   'reduce_dim': SelectKBest(k=5, score_func=<function mutual_info_classif at 0x118d43158>),\n",
       "   'reduce_dim__k': 10},\n",
       "  {'classify': MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "          beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "          hidden_layer_sizes=(3,), learning_rate='constant',\n",
       "          learning_rate_init=0.001, max_iter=100000, momentum=0.2,\n",
       "          nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "          shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "          verbose=False, warm_start=False),\n",
       "   'classify__hidden_layer_sizes': (3,),\n",
       "   'classify__learning_rate': 'constant',\n",
       "   'classify__max_iter': 100000,\n",
       "   'classify__momentum': 0.1,\n",
       "   'reduce_dim': SelectKBest(k=10, score_func=<function f_classif at 0x118c10510>),\n",
       "   'reduce_dim__k': 10},\n",
       "  {'classify': MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "          beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "          hidden_layer_sizes=(3,), learning_rate='constant',\n",
       "          learning_rate_init=0.001, max_iter=100000, momentum=0.2,\n",
       "          nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "          shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "          verbose=False, warm_start=False),\n",
       "   'classify__hidden_layer_sizes': (3,),\n",
       "   'classify__learning_rate': 'constant',\n",
       "   'classify__max_iter': 100000,\n",
       "   'classify__momentum': 0.1,\n",
       "   'reduce_dim': SelectKBest(k=5, score_func=<function mutual_info_classif at 0x118d43158>),\n",
       "   'reduce_dim__k': 10},\n",
       "  {'classify': MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "          beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "          hidden_layer_sizes=(3,), learning_rate='constant',\n",
       "          learning_rate_init=0.001, max_iter=100000, momentum=0.2,\n",
       "          nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "          shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "          verbose=False, warm_start=False),\n",
       "   'classify__hidden_layer_sizes': (3,),\n",
       "   'classify__learning_rate': 'constant',\n",
       "   'classify__max_iter': 100000,\n",
       "   'classify__momentum': 0.2,\n",
       "   'reduce_dim': SelectKBest(k=10, score_func=<function f_classif at 0x118c10510>),\n",
       "   'reduce_dim__k': 10},\n",
       "  {'classify': MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "          beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "          hidden_layer_sizes=(3,), learning_rate='constant',\n",
       "          learning_rate_init=0.001, max_iter=100000, momentum=0.2,\n",
       "          nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "          shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "          verbose=False, warm_start=False),\n",
       "   'classify__hidden_layer_sizes': (3,),\n",
       "   'classify__learning_rate': 'constant',\n",
       "   'classify__max_iter': 100000,\n",
       "   'classify__momentum': 0.2,\n",
       "   'reduce_dim': SelectKBest(k=5, score_func=<function mutual_info_classif at 0x118d43158>),\n",
       "   'reduce_dim__k': 10},\n",
       "  {'classify': MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "          beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "          hidden_layer_sizes=(3,), learning_rate='constant',\n",
       "          learning_rate_init=0.001, max_iter=100000, momentum=0.2,\n",
       "          nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "          shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "          verbose=False, warm_start=False),\n",
       "   'classify__hidden_layer_sizes': (3,),\n",
       "   'classify__learning_rate': 'constant',\n",
       "   'classify__max_iter': 100000,\n",
       "   'classify__momentum': 0.4,\n",
       "   'reduce_dim': SelectKBest(k=10, score_func=<function f_classif at 0x118c10510>),\n",
       "   'reduce_dim__k': 10},\n",
       "  {'classify': MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "          beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "          hidden_layer_sizes=(3,), learning_rate='constant',\n",
       "          learning_rate_init=0.001, max_iter=100000, momentum=0.2,\n",
       "          nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "          shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "          verbose=False, warm_start=False),\n",
       "   'classify__hidden_layer_sizes': (3,),\n",
       "   'classify__learning_rate': 'constant',\n",
       "   'classify__max_iter': 100000,\n",
       "   'classify__momentum': 0.4,\n",
       "   'reduce_dim': SelectKBest(k=5, score_func=<function mutual_info_classif at 0x118d43158>),\n",
       "   'reduce_dim__k': 10},\n",
       "  {'classify': MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "          beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "          hidden_layer_sizes=(3,), learning_rate='constant',\n",
       "          learning_rate_init=0.001, max_iter=100000, momentum=0.2,\n",
       "          nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "          shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "          verbose=False, warm_start=False),\n",
       "   'classify__hidden_layer_sizes': (3,),\n",
       "   'classify__learning_rate': 'constant',\n",
       "   'classify__max_iter': 100000,\n",
       "   'classify__momentum': 0.6,\n",
       "   'reduce_dim': SelectKBest(k=10, score_func=<function f_classif at 0x118c10510>),\n",
       "   'reduce_dim__k': 10},\n",
       "  {'classify': MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "          beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "          hidden_layer_sizes=(3,), learning_rate='constant',\n",
       "          learning_rate_init=0.001, max_iter=100000, momentum=0.2,\n",
       "          nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "          shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "          verbose=False, warm_start=False),\n",
       "   'classify__hidden_layer_sizes': (3,),\n",
       "   'classify__learning_rate': 'constant',\n",
       "   'classify__max_iter': 100000,\n",
       "   'classify__momentum': 0.6,\n",
       "   'reduce_dim': SelectKBest(k=5, score_func=<function mutual_info_classif at 0x118d43158>),\n",
       "   'reduce_dim__k': 10},\n",
       "  {'classify': MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "          beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "          hidden_layer_sizes=(3,), learning_rate='constant',\n",
       "          learning_rate_init=0.001, max_iter=100000, momentum=0.2,\n",
       "          nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "          shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "          verbose=False, warm_start=False),\n",
       "   'classify__hidden_layer_sizes': (3,),\n",
       "   'classify__learning_rate': 'constant',\n",
       "   'classify__max_iter': 100000,\n",
       "   'classify__momentum': 0.8,\n",
       "   'reduce_dim': SelectKBest(k=10, score_func=<function f_classif at 0x118c10510>),\n",
       "   'reduce_dim__k': 10},\n",
       "  {'classify': MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "          beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "          hidden_layer_sizes=(3,), learning_rate='constant',\n",
       "          learning_rate_init=0.001, max_iter=100000, momentum=0.2,\n",
       "          nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "          shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "          verbose=False, warm_start=False),\n",
       "   'classify__hidden_layer_sizes': (3,),\n",
       "   'classify__learning_rate': 'constant',\n",
       "   'classify__max_iter': 100000,\n",
       "   'classify__momentum': 0.8,\n",
       "   'reduce_dim': SelectKBest(k=5, score_func=<function mutual_info_classif at 0x118d43158>),\n",
       "   'reduce_dim__k': 10},\n",
       "  {'classify': MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "          beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "          hidden_layer_sizes=(3,), learning_rate='constant',\n",
       "          learning_rate_init=0.001, max_iter=100000, momentum=0.2,\n",
       "          nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "          shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "          verbose=False, warm_start=False),\n",
       "   'classify__hidden_layer_sizes': (3,),\n",
       "   'classify__learning_rate': 'constant',\n",
       "   'classify__max_iter': 100000,\n",
       "   'classify__momentum': 0.9,\n",
       "   'reduce_dim': SelectKBest(k=10, score_func=<function f_classif at 0x118c10510>),\n",
       "   'reduce_dim__k': 10},\n",
       "  {'classify': MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "          beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "          hidden_layer_sizes=(3,), learning_rate='constant',\n",
       "          learning_rate_init=0.001, max_iter=100000, momentum=0.2,\n",
       "          nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "          shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "          verbose=False, warm_start=False),\n",
       "   'classify__hidden_layer_sizes': (3,),\n",
       "   'classify__learning_rate': 'constant',\n",
       "   'classify__max_iter': 100000,\n",
       "   'classify__momentum': 0.9,\n",
       "   'reduce_dim': SelectKBest(k=5, score_func=<function mutual_info_classif at 0x118d43158>),\n",
       "   'reduce_dim__k': 10},\n",
       "  {'classify': MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "          beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "          hidden_layer_sizes=(3,), learning_rate='constant',\n",
       "          learning_rate_init=0.001, max_iter=100000, momentum=0.2,\n",
       "          nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "          shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "          verbose=False, warm_start=False),\n",
       "   'classify__hidden_layer_sizes': (6,),\n",
       "   'classify__learning_rate': 'constant',\n",
       "   'classify__max_iter': 100000,\n",
       "   'classify__momentum': 0.01,\n",
       "   'reduce_dim': SelectKBest(k=10, score_func=<function f_classif at 0x118c10510>),\n",
       "   'reduce_dim__k': 10},\n",
       "  {'classify': MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "          beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "          hidden_layer_sizes=(3,), learning_rate='constant',\n",
       "          learning_rate_init=0.001, max_iter=100000, momentum=0.2,\n",
       "          nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "          shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "          verbose=False, warm_start=False),\n",
       "   'classify__hidden_layer_sizes': (6,),\n",
       "   'classify__learning_rate': 'constant',\n",
       "   'classify__max_iter': 100000,\n",
       "   'classify__momentum': 0.01,\n",
       "   'reduce_dim': SelectKBest(k=5, score_func=<function mutual_info_classif at 0x118d43158>),\n",
       "   'reduce_dim__k': 10},\n",
       "  {'classify': MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "          beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "          hidden_layer_sizes=(3,), learning_rate='constant',\n",
       "          learning_rate_init=0.001, max_iter=100000, momentum=0.2,\n",
       "          nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "          shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "          verbose=False, warm_start=False),\n",
       "   'classify__hidden_layer_sizes': (6,),\n",
       "   'classify__learning_rate': 'constant',\n",
       "   'classify__max_iter': 100000,\n",
       "   'classify__momentum': 0.05,\n",
       "   'reduce_dim': SelectKBest(k=10, score_func=<function f_classif at 0x118c10510>),\n",
       "   'reduce_dim__k': 10},\n",
       "  {'classify': MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "          beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "          hidden_layer_sizes=(3,), learning_rate='constant',\n",
       "          learning_rate_init=0.001, max_iter=100000, momentum=0.2,\n",
       "          nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "          shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "          verbose=False, warm_start=False),\n",
       "   'classify__hidden_layer_sizes': (6,),\n",
       "   'classify__learning_rate': 'constant',\n",
       "   'classify__max_iter': 100000,\n",
       "   'classify__momentum': 0.05,\n",
       "   'reduce_dim': SelectKBest(k=5, score_func=<function mutual_info_classif at 0x118d43158>),\n",
       "   'reduce_dim__k': 10},\n",
       "  {'classify': MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "          beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "          hidden_layer_sizes=(3,), learning_rate='constant',\n",
       "          learning_rate_init=0.001, max_iter=100000, momentum=0.2,\n",
       "          nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "          shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "          verbose=False, warm_start=False),\n",
       "   'classify__hidden_layer_sizes': (6,),\n",
       "   'classify__learning_rate': 'constant',\n",
       "   'classify__max_iter': 100000,\n",
       "   'classify__momentum': 0.1,\n",
       "   'reduce_dim': SelectKBest(k=10, score_func=<function f_classif at 0x118c10510>),\n",
       "   'reduce_dim__k': 10},\n",
       "  {'classify': MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "          beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "          hidden_layer_sizes=(3,), learning_rate='constant',\n",
       "          learning_rate_init=0.001, max_iter=100000, momentum=0.2,\n",
       "          nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "          shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "          verbose=False, warm_start=False),\n",
       "   'classify__hidden_layer_sizes': (6,),\n",
       "   'classify__learning_rate': 'constant',\n",
       "   'classify__max_iter': 100000,\n",
       "   'classify__momentum': 0.1,\n",
       "   'reduce_dim': SelectKBest(k=5, score_func=<function mutual_info_classif at 0x118d43158>),\n",
       "   'reduce_dim__k': 10},\n",
       "  {'classify': MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "          beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "          hidden_layer_sizes=(3,), learning_rate='constant',\n",
       "          learning_rate_init=0.001, max_iter=100000, momentum=0.2,\n",
       "          nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "          shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "          verbose=False, warm_start=False),\n",
       "   'classify__hidden_layer_sizes': (6,),\n",
       "   'classify__learning_rate': 'constant',\n",
       "   'classify__max_iter': 100000,\n",
       "   'classify__momentum': 0.2,\n",
       "   'reduce_dim': SelectKBest(k=10, score_func=<function f_classif at 0x118c10510>),\n",
       "   'reduce_dim__k': 10},\n",
       "  {'classify': MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "          beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "          hidden_layer_sizes=(3,), learning_rate='constant',\n",
       "          learning_rate_init=0.001, max_iter=100000, momentum=0.2,\n",
       "          nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "          shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "          verbose=False, warm_start=False),\n",
       "   'classify__hidden_layer_sizes': (6,),\n",
       "   'classify__learning_rate': 'constant',\n",
       "   'classify__max_iter': 100000,\n",
       "   'classify__momentum': 0.2,\n",
       "   'reduce_dim': SelectKBest(k=5, score_func=<function mutual_info_classif at 0x118d43158>),\n",
       "   'reduce_dim__k': 10},\n",
       "  {'classify': MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "          beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "          hidden_layer_sizes=(3,), learning_rate='constant',\n",
       "          learning_rate_init=0.001, max_iter=100000, momentum=0.2,\n",
       "          nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "          shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "          verbose=False, warm_start=False),\n",
       "   'classify__hidden_layer_sizes': (6,),\n",
       "   'classify__learning_rate': 'constant',\n",
       "   'classify__max_iter': 100000,\n",
       "   'classify__momentum': 0.4,\n",
       "   'reduce_dim': SelectKBest(k=10, score_func=<function f_classif at 0x118c10510>),\n",
       "   'reduce_dim__k': 10},\n",
       "  {'classify': MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "          beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "          hidden_layer_sizes=(3,), learning_rate='constant',\n",
       "          learning_rate_init=0.001, max_iter=100000, momentum=0.2,\n",
       "          nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "          shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "          verbose=False, warm_start=False),\n",
       "   'classify__hidden_layer_sizes': (6,),\n",
       "   'classify__learning_rate': 'constant',\n",
       "   'classify__max_iter': 100000,\n",
       "   'classify__momentum': 0.4,\n",
       "   'reduce_dim': SelectKBest(k=5, score_func=<function mutual_info_classif at 0x118d43158>),\n",
       "   'reduce_dim__k': 10},\n",
       "  {'classify': MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "          beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "          hidden_layer_sizes=(3,), learning_rate='constant',\n",
       "          learning_rate_init=0.001, max_iter=100000, momentum=0.2,\n",
       "          nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "          shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "          verbose=False, warm_start=False),\n",
       "   'classify__hidden_layer_sizes': (6,),\n",
       "   'classify__learning_rate': 'constant',\n",
       "   'classify__max_iter': 100000,\n",
       "   'classify__momentum': 0.6,\n",
       "   'reduce_dim': SelectKBest(k=10, score_func=<function f_classif at 0x118c10510>),\n",
       "   'reduce_dim__k': 10},\n",
       "  {'classify': MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "          beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "          hidden_layer_sizes=(3,), learning_rate='constant',\n",
       "          learning_rate_init=0.001, max_iter=100000, momentum=0.2,\n",
       "          nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "          shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "          verbose=False, warm_start=False),\n",
       "   'classify__hidden_layer_sizes': (6,),\n",
       "   'classify__learning_rate': 'constant',\n",
       "   'classify__max_iter': 100000,\n",
       "   'classify__momentum': 0.6,\n",
       "   'reduce_dim': SelectKBest(k=5, score_func=<function mutual_info_classif at 0x118d43158>),\n",
       "   'reduce_dim__k': 10},\n",
       "  {'classify': MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "          beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "          hidden_layer_sizes=(3,), learning_rate='constant',\n",
       "          learning_rate_init=0.001, max_iter=100000, momentum=0.2,\n",
       "          nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "          shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "          verbose=False, warm_start=False),\n",
       "   'classify__hidden_layer_sizes': (6,),\n",
       "   'classify__learning_rate': 'constant',\n",
       "   'classify__max_iter': 100000,\n",
       "   'classify__momentum': 0.8,\n",
       "   'reduce_dim': SelectKBest(k=10, score_func=<function f_classif at 0x118c10510>),\n",
       "   'reduce_dim__k': 10},\n",
       "  {'classify': MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "          beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "          hidden_layer_sizes=(3,), learning_rate='constant',\n",
       "          learning_rate_init=0.001, max_iter=100000, momentum=0.2,\n",
       "          nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "          shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "          verbose=False, warm_start=False),\n",
       "   'classify__hidden_layer_sizes': (6,),\n",
       "   'classify__learning_rate': 'constant',\n",
       "   'classify__max_iter': 100000,\n",
       "   'classify__momentum': 0.8,\n",
       "   'reduce_dim': SelectKBest(k=5, score_func=<function mutual_info_classif at 0x118d43158>),\n",
       "   'reduce_dim__k': 10},\n",
       "  {'classify': MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "          beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "          hidden_layer_sizes=(3,), learning_rate='constant',\n",
       "          learning_rate_init=0.001, max_iter=100000, momentum=0.2,\n",
       "          nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "          shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "          verbose=False, warm_start=False),\n",
       "   'classify__hidden_layer_sizes': (6,),\n",
       "   'classify__learning_rate': 'constant',\n",
       "   'classify__max_iter': 100000,\n",
       "   'classify__momentum': 0.9,\n",
       "   'reduce_dim': SelectKBest(k=10, score_func=<function f_classif at 0x118c10510>),\n",
       "   'reduce_dim__k': 10},\n",
       "  {'classify': MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "          beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "          hidden_layer_sizes=(3,), learning_rate='constant',\n",
       "          learning_rate_init=0.001, max_iter=100000, momentum=0.2,\n",
       "          nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "          shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "          verbose=False, warm_start=False),\n",
       "   'classify__hidden_layer_sizes': (6,),\n",
       "   'classify__learning_rate': 'constant',\n",
       "   'classify__max_iter': 100000,\n",
       "   'classify__momentum': 0.9,\n",
       "   'reduce_dim': SelectKBest(k=5, score_func=<function mutual_info_classif at 0x118d43158>),\n",
       "   'reduce_dim__k': 10}],\n",
       " 'rank_test_accuracy': array([61, 10, 48, 41, 17, 17, 28, 17, 10, 17, 55,  4, 37, 10, 37, 10,  1,\n",
       "        17, 61,  4, 41,  7, 28,  2, 47, 24, 24, 28, 41,  7, 28, 37, 48, 24,\n",
       "        41, 55, 17, 58, 41, 41, 28, 28, 64, 50, 60, 28, 16, 50, 10, 17, 55,\n",
       "        28, 50,  2, 61,  6, 28, 50, 58, 37, 24,  7, 10, 50], dtype=int32),\n",
       " 'rank_test_au_prc_macro': array([33, 11, 18, 55, 33,  7, 57, 33, 47, 23, 33,  6, 32, 29, 23, 14,  2,\n",
       "        22, 62, 64, 33, 13, 48,  1, 25, 60,  9, 33, 10, 20, 17, 43, 52, 26,\n",
       "        33, 33, 49, 12, 46, 59, 27, 15, 31, 56, 63, 53, 50, 30,  8, 19, 58,\n",
       "         5, 21,  4, 54, 16, 33, 51, 28, 44, 45, 61,  3, 33], dtype=int32),\n",
       " 'rank_test_au_prc_micro': array([33, 11, 18, 55, 33,  7, 57, 33, 47, 23, 33,  6, 32, 29, 23, 14,  2,\n",
       "        22, 62, 64, 33, 13, 48,  1, 25, 60,  9, 33, 10, 20, 17, 43, 52, 26,\n",
       "        33, 33, 49, 12, 46, 59, 27, 15, 31, 56, 63, 53, 50, 30,  8, 19, 58,\n",
       "         5, 21,  4, 54, 16, 33, 51, 28, 44, 45, 61,  3, 33], dtype=int32),\n",
       " 'rank_test_f1_macro': array([63,  8, 55, 40, 42, 27, 34, 41, 18, 26, 59,  4, 39, 20, 33, 16,  1,\n",
       "        17, 31,  6, 53,  7, 35,  2, 38, 28, 14, 45, 30, 10, 15, 49, 54, 29,\n",
       "        51, 58, 43, 60, 19, 44, 36, 21, 64, 37, 61, 23, 24, 48, 12, 25, 46,\n",
       "        32, 57,  3, 62,  9, 47, 50, 52, 13, 22, 11,  5, 56], dtype=int32),\n",
       " 'rank_test_f1_micro': array([61, 10, 48, 41, 17, 17, 28, 17, 10, 17, 55,  4, 37, 10, 37, 10,  1,\n",
       "        17, 61,  4, 41,  7, 28,  2, 47, 24, 24, 28, 41,  7, 28, 37, 48, 24,\n",
       "        41, 55, 17, 58, 41, 41, 28, 28, 64, 50, 60, 28, 16, 50, 10, 17, 55,\n",
       "        28, 50,  2, 61,  6, 28, 50, 58, 37, 24,  7, 10, 50], dtype=int32),\n",
       " 'rank_test_precision_macro': array([64,  8, 56, 43, 47, 34, 38, 47, 21, 18, 61,  1, 22, 32, 25, 20,  3,\n",
       "        29, 11,  7, 53,  4, 31,  6, 26, 36, 17, 51, 35, 10, 23, 52, 57, 33,\n",
       "        53, 61, 45, 55, 13, 40, 39, 12, 46, 15, 60, 19, 14, 41, 24, 30, 42,\n",
       "        37, 58,  2, 63,  9, 50, 44, 49, 16, 28, 27,  5, 59], dtype=int32),\n",
       " 'rank_test_precision_micro': array([61, 10, 48, 41, 17, 17, 28, 17, 10, 17, 55,  4, 37, 10, 37, 10,  1,\n",
       "        17, 61,  4, 41,  7, 28,  2, 47, 24, 24, 28, 41,  7, 28, 37, 48, 24,\n",
       "        41, 55, 17, 58, 41, 41, 28, 28, 64, 50, 60, 28, 16, 50, 10, 17, 55,\n",
       "        28, 50,  2, 61,  6, 28, 50, 58, 37, 24,  7, 10, 50], dtype=int32),\n",
       " 'split0_test_accuracy': array([ 0.34482759,  0.27586207,  0.37931034,  0.34482759,  0.34482759,\n",
       "         0.37931034,  0.37931034,  0.37931034,  0.48275862,  0.27586207,\n",
       "         0.27586207,  0.5862069 ,  0.34482759,  0.34482759,  0.27586207,\n",
       "         0.51724138,  0.37931034,  0.48275862,  0.27586207,  0.51724138,\n",
       "         0.37931034,  0.37931034,  0.31034483,  0.34482759,  0.34482759,\n",
       "         0.37931034,  0.51724138,  0.34482759,  0.34482759,  0.4137931 ,\n",
       "         0.27586207,  0.27586207,  0.37931034,  0.37931034,  0.34482759,\n",
       "         0.34482759,  0.37931034,  0.37931034,  0.4137931 ,  0.37931034,\n",
       "         0.37931034,  0.34482759,  0.24137931,  0.34482759,  0.27586207,\n",
       "         0.37931034,  0.44827586,  0.4137931 ,  0.27586207,  0.44827586,\n",
       "         0.37931034,  0.27586207,  0.37931034,  0.44827586,  0.27586207,\n",
       "         0.55172414,  0.34482759,  0.34482759,  0.27586207,  0.37931034,\n",
       "         0.48275862,  0.34482759,  0.27586207,  0.27586207]),\n",
       " 'split0_test_au_prc_macro': array([ 0.5       ,  0.5       ,  0.5       ,  0.5       ,  0.5       ,\n",
       "         0.5       ,  0.5       ,  0.5       ,  0.4693609 ,  0.5       ,\n",
       "         0.5       ,  0.68639528,  0.5       ,  0.5       ,  0.5       ,\n",
       "         0.68327068,  0.5       ,  0.68764098,  0.5       ,  0.27670739,\n",
       "         0.5       ,  0.5       ,  0.49749373,  0.5       ,  0.5       ,\n",
       "         0.5       ,  0.72203947,  0.5       ,  0.5       ,  0.54994146,\n",
       "         0.5       ,  0.5       ,  0.5       ,  0.5       ,  0.5       ,\n",
       "         0.5       ,  0.5       ,  0.5       ,  0.40993108,  0.5       ,\n",
       "         0.5       ,  0.5       ,  0.55316416,  0.45308584,  0.5       ,\n",
       "         0.5       ,  0.5037594 ,  0.52940163,  0.5       ,  0.60070489,\n",
       "         0.5       ,  0.5       ,  0.5       ,  0.66448935,  0.5       ,\n",
       "         0.65105504,  0.5       ,  0.5       ,  0.5       ,  0.5       ,\n",
       "         0.43370927,  0.5       ,  0.5       ,  0.5       ]),\n",
       " 'split0_test_au_prc_micro': array([ 0.5       ,  0.5       ,  0.5       ,  0.5       ,  0.5       ,\n",
       "         0.5       ,  0.5       ,  0.5       ,  0.4693609 ,  0.5       ,\n",
       "         0.5       ,  0.68639528,  0.5       ,  0.5       ,  0.5       ,\n",
       "         0.68327068,  0.5       ,  0.68764098,  0.5       ,  0.27670739,\n",
       "         0.5       ,  0.5       ,  0.49749373,  0.5       ,  0.5       ,\n",
       "         0.5       ,  0.72203947,  0.5       ,  0.5       ,  0.54994146,\n",
       "         0.5       ,  0.5       ,  0.5       ,  0.5       ,  0.5       ,\n",
       "         0.5       ,  0.5       ,  0.5       ,  0.40993108,  0.5       ,\n",
       "         0.5       ,  0.5       ,  0.55316416,  0.45308584,  0.5       ,\n",
       "         0.5       ,  0.5037594 ,  0.52940163,  0.5       ,  0.60070489,\n",
       "         0.5       ,  0.5       ,  0.5       ,  0.66448935,  0.5       ,\n",
       "         0.65105504,  0.5       ,  0.5       ,  0.5       ,  0.5       ,\n",
       "         0.43370927,  0.5       ,  0.5       ,  0.5       ]),\n",
       " 'split0_test_f1_macro': array([ 0.17094017,  0.14414414,  0.18333333,  0.17094017,  0.17094017,\n",
       "         0.18333333,  0.18333333,  0.18333333,  0.37789661,  0.14414414,\n",
       "         0.14414414,  0.58109041,  0.17094017,  0.17094017,  0.14414414,\n",
       "         0.40441176,  0.18333333,  0.40188172,  0.14414414,  0.43417367,\n",
       "         0.18333333,  0.18333333,  0.15789474,  0.17094017,  0.17094017,\n",
       "         0.18333333,  0.45248869,  0.17094017,  0.17094017,  0.3740752 ,\n",
       "         0.14414414,  0.14414414,  0.18333333,  0.18333333,  0.17094017,\n",
       "         0.17094017,  0.18333333,  0.18333333,  0.3013923 ,  0.18333333,\n",
       "         0.18333333,  0.17094017,  0.16565657,  0.22276822,  0.14414414,\n",
       "         0.18333333,  0.32804233,  0.25880426,  0.14414414,  0.33868093,\n",
       "         0.18333333,  0.14414414,  0.18333333,  0.38148148,  0.14414414,\n",
       "         0.52393162,  0.17094017,  0.17094017,  0.14414414,  0.18333333,\n",
       "         0.39443436,  0.17094017,  0.14414414,  0.14414414]),\n",
       " 'split0_test_f1_micro': array([ 0.34482759,  0.27586207,  0.37931034,  0.34482759,  0.34482759,\n",
       "         0.37931034,  0.37931034,  0.37931034,  0.48275862,  0.27586207,\n",
       "         0.27586207,  0.5862069 ,  0.34482759,  0.34482759,  0.27586207,\n",
       "         0.51724138,  0.37931034,  0.48275862,  0.27586207,  0.51724138,\n",
       "         0.37931034,  0.37931034,  0.31034483,  0.34482759,  0.34482759,\n",
       "         0.37931034,  0.51724138,  0.34482759,  0.34482759,  0.4137931 ,\n",
       "         0.27586207,  0.27586207,  0.37931034,  0.37931034,  0.34482759,\n",
       "         0.34482759,  0.37931034,  0.37931034,  0.4137931 ,  0.37931034,\n",
       "         0.37931034,  0.34482759,  0.24137931,  0.34482759,  0.27586207,\n",
       "         0.37931034,  0.44827586,  0.4137931 ,  0.27586207,  0.44827586,\n",
       "         0.37931034,  0.27586207,  0.37931034,  0.44827586,  0.27586207,\n",
       "         0.55172414,  0.34482759,  0.34482759,  0.27586207,  0.37931034,\n",
       "         0.48275862,  0.34482759,  0.27586207,  0.27586207]),\n",
       " 'split0_test_precision_macro': array([ 0.11494253,  0.09195402,  0.12643678,  0.11494253,  0.11494253,\n",
       "         0.12643678,  0.12643678,  0.12643678,  0.40821256,  0.09195402,\n",
       "         0.09195402,  0.59401709,  0.11494253,  0.11494253,  0.09195402,\n",
       "         0.42270531,  0.12643678,  0.35119048,  0.09195402,  0.42270531,\n",
       "         0.12643678,  0.12643678,  0.11111111,  0.11494253,  0.11494253,\n",
       "         0.12643678,  0.47222222,  0.11494253,  0.11494253,  0.36270396,\n",
       "         0.09195402,  0.09195402,  0.12643678,  0.12643678,  0.11494253,\n",
       "         0.11494253,  0.12643678,  0.12643678,  0.35042735,  0.12643678,\n",
       "         0.12643678,  0.11494253,  0.16333333,  0.22649573,  0.09195402,\n",
       "         0.12643678,  0.46153846,  0.25213675,  0.09195402,  0.32683983,\n",
       "         0.12643678,  0.09195402,  0.12643678,  0.3120915 ,  0.09195402,\n",
       "         0.57175926,  0.11494253,  0.11494253,  0.09195402,  0.12643678,\n",
       "         0.37698413,  0.11494253,  0.09195402,  0.09195402]),\n",
       " 'split0_test_precision_micro': array([ 0.34482759,  0.27586207,  0.37931034,  0.34482759,  0.34482759,\n",
       "         0.37931034,  0.37931034,  0.37931034,  0.48275862,  0.27586207,\n",
       "         0.27586207,  0.5862069 ,  0.34482759,  0.34482759,  0.27586207,\n",
       "         0.51724138,  0.37931034,  0.48275862,  0.27586207,  0.51724138,\n",
       "         0.37931034,  0.37931034,  0.31034483,  0.34482759,  0.34482759,\n",
       "         0.37931034,  0.51724138,  0.34482759,  0.34482759,  0.4137931 ,\n",
       "         0.27586207,  0.27586207,  0.37931034,  0.37931034,  0.34482759,\n",
       "         0.34482759,  0.37931034,  0.37931034,  0.4137931 ,  0.37931034,\n",
       "         0.37931034,  0.34482759,  0.24137931,  0.34482759,  0.27586207,\n",
       "         0.37931034,  0.44827586,  0.4137931 ,  0.27586207,  0.44827586,\n",
       "         0.37931034,  0.27586207,  0.37931034,  0.44827586,  0.27586207,\n",
       "         0.55172414,  0.34482759,  0.34482759,  0.27586207,  0.37931034,\n",
       "         0.48275862,  0.34482759,  0.27586207,  0.27586207]),\n",
       " 'split1_test_accuracy': array([ 0.25925926,  0.62962963,  0.37037037,  0.37037037,  0.37037037,\n",
       "         0.37037037,  0.37037037,  0.37037037,  0.37037037,  0.37037037,\n",
       "         0.25925926,  0.37037037,  0.40740741,  0.37037037,  0.25925926,\n",
       "         0.37037037,  0.37037037,  0.25925926,  0.51851852,  0.37037037,\n",
       "         0.25925926,  0.51851852,  0.37037037,  0.55555556,  0.33333333,\n",
       "         0.37037037,  0.37037037,  0.37037037,  0.25925926,  0.40740741,\n",
       "         0.25925926,  0.37037037,  0.37037037,  0.33333333,  0.37037037,\n",
       "         0.37037037,  0.37037037,  0.11111111,  0.25925926,  0.2962963 ,\n",
       "         0.37037037,  0.40740741,  0.11111111,  0.25925926,  0.37037037,\n",
       "         0.33333333,  0.37037037,  0.25925926,  0.55555556,  0.37037037,\n",
       "         0.37037037,  0.40740741,  0.37037037,  0.37037037,  0.25925926,\n",
       "         0.37037037,  0.37037037,  0.37037037,  0.2962963 ,  0.22222222,\n",
       "         0.37037037,  0.37037037,  0.55555556,  0.37037037]),\n",
       " 'split1_test_au_prc_macro': array([ 0.5       ,  0.72962185,  0.5       ,  0.5       ,  0.5       ,\n",
       "         0.5       ,  0.5       ,  0.5       ,  0.5       ,  0.5       ,\n",
       "         0.5       ,  0.5       ,  0.50220588,  0.5       ,  0.5       ,\n",
       "         0.5       ,  0.5       ,  0.5       ,  0.62016807,  0.5       ,\n",
       "         0.5       ,  0.65      ,  0.5       ,  0.79117647,  0.575     ,\n",
       "         0.5       ,  0.5       ,  0.5       ,  0.5       ,  0.55262605,\n",
       "         0.5       ,  0.5       ,  0.5       ,  0.55766807,  0.5       ,\n",
       "         0.5       ,  0.5       ,  0.71680672,  0.5       ,  0.38970588,\n",
       "         0.5       ,  0.58403361,  0.51418067,  0.5       ,  0.5       ,\n",
       "         0.57279412,  0.5       ,  0.5       ,  0.75430672,  0.5       ,\n",
       "         0.5       ,  0.78455882,  0.5       ,  0.5       ,  0.5       ,\n",
       "         0.5       ,  0.5       ,  0.5       ,  0.55105042,  0.42037815,\n",
       "         0.5       ,  0.5       ,  0.77163866,  0.5       ]),\n",
       " 'split1_test_au_prc_micro': array([ 0.5       ,  0.72962185,  0.5       ,  0.5       ,  0.5       ,\n",
       "         0.5       ,  0.5       ,  0.5       ,  0.5       ,  0.5       ,\n",
       "         0.5       ,  0.5       ,  0.50220588,  0.5       ,  0.5       ,\n",
       "         0.5       ,  0.5       ,  0.5       ,  0.62016807,  0.5       ,\n",
       "         0.5       ,  0.65      ,  0.5       ,  0.79117647,  0.575     ,\n",
       "         0.5       ,  0.5       ,  0.5       ,  0.5       ,  0.55262605,\n",
       "         0.5       ,  0.5       ,  0.5       ,  0.55766807,  0.5       ,\n",
       "         0.5       ,  0.5       ,  0.71680672,  0.5       ,  0.38970588,\n",
       "         0.5       ,  0.58403361,  0.51418067,  0.5       ,  0.5       ,\n",
       "         0.57279412,  0.5       ,  0.5       ,  0.75430672,  0.5       ,\n",
       "         0.5       ,  0.78455882,  0.5       ,  0.5       ,  0.5       ,\n",
       "         0.5       ,  0.5       ,  0.5       ,  0.55105042,  0.42037815,\n",
       "         0.5       ,  0.5       ,  0.77163866,  0.5       ]),\n",
       " 'split1_test_f1_macro': array([ 0.1372549 ,  0.64547558,  0.18018018,  0.18018018,  0.18018018,\n",
       "         0.18018018,  0.18018018,  0.18018018,  0.18018018,  0.18018018,\n",
       "         0.1372549 ,  0.18018018,  0.24579125,  0.18018018,  0.1372549 ,\n",
       "         0.18018018,  0.18018018,  0.1372549 ,  0.48148148,  0.18018018,\n",
       "         0.1372549 ,  0.39249639,  0.18018018,  0.45454545,  0.25694444,\n",
       "         0.18018018,  0.18018018,  0.18018018,  0.1372549 ,  0.24603175,\n",
       "         0.1372549 ,  0.18018018,  0.18018018,  0.26785714,  0.18018018,\n",
       "         0.18018018,  0.18018018,  0.0885984 ,  0.1372549 ,  0.2031746 ,\n",
       "         0.18018018,  0.36981948,  0.08      ,  0.1372549 ,  0.18018018,\n",
       "         0.17647059,  0.18018018,  0.1372549 ,  0.47146402,  0.18018018,\n",
       "         0.18018018,  0.30424242,  0.18018018,  0.18018018,  0.1372549 ,\n",
       "         0.18018018,  0.18018018,  0.18018018,  0.22431078,  0.18326118,\n",
       "         0.18018018,  0.18018018,  0.45751634,  0.18018018]),\n",
       " 'split1_test_f1_micro': array([ 0.25925926,  0.62962963,  0.37037037,  0.37037037,  0.37037037,\n",
       "         0.37037037,  0.37037037,  0.37037037,  0.37037037,  0.37037037,\n",
       "         0.25925926,  0.37037037,  0.40740741,  0.37037037,  0.25925926,\n",
       "         0.37037037,  0.37037037,  0.25925926,  0.51851852,  0.37037037,\n",
       "         0.25925926,  0.51851852,  0.37037037,  0.55555556,  0.33333333,\n",
       "         0.37037037,  0.37037037,  0.37037037,  0.25925926,  0.40740741,\n",
       "         0.25925926,  0.37037037,  0.37037037,  0.33333333,  0.37037037,\n",
       "         0.37037037,  0.37037037,  0.11111111,  0.25925926,  0.2962963 ,\n",
       "         0.37037037,  0.40740741,  0.11111111,  0.25925926,  0.37037037,\n",
       "         0.33333333,  0.37037037,  0.25925926,  0.55555556,  0.37037037,\n",
       "         0.37037037,  0.40740741,  0.37037037,  0.37037037,  0.25925926,\n",
       "         0.37037037,  0.37037037,  0.37037037,  0.2962963 ,  0.22222222,\n",
       "         0.37037037,  0.37037037,  0.55555556,  0.37037037]),\n",
       " 'split1_test_precision_macro': array([ 0.08641975,  0.65567766,  0.12345679,  0.12345679,  0.12345679,\n",
       "         0.12345679,  0.12345679,  0.12345679,  0.12345679,  0.12345679,\n",
       "         0.08641975,  0.12345679,  0.46153846,  0.12345679,  0.08641975,\n",
       "         0.12345679,  0.12345679,  0.08641975,  0.68333333,  0.12345679,\n",
       "         0.08641975,  0.47826087,  0.12345679,  0.37777778,  0.42666667,\n",
       "         0.12345679,  0.12345679,  0.12345679,  0.08641975,  0.3       ,\n",
       "         0.08641975,  0.12345679,  0.12345679,  0.26190476,  0.12345679,\n",
       "         0.12345679,  0.12345679,  0.08095238,  0.08641975,  0.18478261,\n",
       "         0.12345679,  0.43981481,  0.05555556,  0.08641975,  0.12345679,\n",
       "         0.125     ,  0.12345679,  0.08641975,  0.43650794,  0.12345679,\n",
       "         0.12345679,  0.26111111,  0.12345679,  0.12345679,  0.08641975,\n",
       "         0.12345679,  0.12345679,  0.12345679,  0.2037037 ,  0.16269841,\n",
       "         0.12345679,  0.12345679,  0.37647059,  0.12345679]),\n",
       " 'split1_test_precision_micro': array([ 0.25925926,  0.62962963,  0.37037037,  0.37037037,  0.37037037,\n",
       "         0.37037037,  0.37037037,  0.37037037,  0.37037037,  0.37037037,\n",
       "         0.25925926,  0.37037037,  0.40740741,  0.37037037,  0.25925926,\n",
       "         0.37037037,  0.37037037,  0.25925926,  0.51851852,  0.37037037,\n",
       "         0.25925926,  0.51851852,  0.37037037,  0.55555556,  0.33333333,\n",
       "         0.37037037,  0.37037037,  0.37037037,  0.25925926,  0.40740741,\n",
       "         0.25925926,  0.37037037,  0.37037037,  0.33333333,  0.37037037,\n",
       "         0.37037037,  0.37037037,  0.11111111,  0.25925926,  0.2962963 ,\n",
       "         0.37037037,  0.40740741,  0.11111111,  0.25925926,  0.37037037,\n",
       "         0.33333333,  0.37037037,  0.25925926,  0.55555556,  0.37037037,\n",
       "         0.37037037,  0.40740741,  0.37037037,  0.37037037,  0.25925926,\n",
       "         0.37037037,  0.37037037,  0.37037037,  0.2962963 ,  0.22222222,\n",
       "         0.37037037,  0.37037037,  0.55555556,  0.37037037]),\n",
       " 'split2_test_accuracy': array([ 0.26923077,  0.26923077,  0.15384615,  0.34615385,  0.34615385,\n",
       "         0.38461538,  0.26923077,  0.34615385,  0.38461538,  0.42307692,\n",
       "         0.26923077,  0.30769231,  0.34615385,  0.30769231,  0.42307692,\n",
       "         0.38461538,  0.61538462,  0.38461538,  0.26923077,  0.42307692,\n",
       "         0.34615385,  0.42307692,  0.34615385,  0.53846154,  0.34615385,\n",
       "         0.38461538,  0.26923077,  0.34615385,  0.34615385,  0.34615385,\n",
       "         0.46153846,  0.34615385,  0.26923077,  0.34615385,  0.34615385,\n",
       "         0.26923077,  0.38461538,  0.38461538,  0.46153846,  0.34615385,\n",
       "         0.38461538,  0.23076923,  0.26923077,  0.26923077,  0.07692308,\n",
       "         0.5       ,  0.38461538,  0.26923077,  0.34615385,  0.34615385,\n",
       "         0.19230769,  0.34615385,  0.15384615,  0.38461538,  0.34615385,\n",
       "         0.34615385,  0.26923077,  0.26923077,  0.26923077,  0.34615385,\n",
       "         0.34615385,  0.61538462,  0.26923077,  0.26923077]),\n",
       " 'split2_test_au_prc_macro': array([ 0.5       ,  0.5       ,  0.6512605 ,  0.5       ,  0.5       ,\n",
       "         0.5       ,  0.5       ,  0.5       ,  0.5       ,  0.60084034,\n",
       "         0.5       ,  0.55990466,  0.5       ,  0.49690402,  0.60084034,\n",
       "         0.5       ,  0.71582828,  0.39915966,  0.5       ,  0.39441742,\n",
       "         0.5       ,  0.56837478,  0.4621603 ,  0.77106983,  0.5       ,\n",
       "         0.5       ,  0.5       ,  0.5       ,  0.5       ,  0.5       ,\n",
       "         0.58816158,  0.49845201,  0.5       ,  0.5       ,  0.5       ,\n",
       "         0.5       ,  0.5       ,  0.5       ,  0.57296734,  0.5       ,\n",
       "         0.55351614,  0.60238832,  0.5       ,  0.5       ,  0.18509509,\n",
       "         0.46680427,  0.5       ,  0.5       ,  0.5       ,  0.5       ,\n",
       "         0.26851442,  0.5       ,  0.61032483,  0.5       ,  0.5       ,\n",
       "         0.5       ,  0.5       ,  0.5       ,  0.5       ,  0.5       ,\n",
       "         0.5       ,  0.3501892 ,  0.5       ,  0.5       ]),\n",
       " 'split2_test_au_prc_micro': array([ 0.5       ,  0.5       ,  0.6512605 ,  0.5       ,  0.5       ,\n",
       "         0.5       ,  0.5       ,  0.5       ,  0.5       ,  0.60084034,\n",
       "         0.5       ,  0.55990466,  0.5       ,  0.49690402,  0.60084034,\n",
       "         0.5       ,  0.71582828,  0.39915966,  0.5       ,  0.39441742,\n",
       "         0.5       ,  0.56837478,  0.4621603 ,  0.77106983,  0.5       ,\n",
       "         0.5       ,  0.5       ,  0.5       ,  0.5       ,  0.5       ,\n",
       "         0.58816158,  0.49845201,  0.5       ,  0.5       ,  0.5       ,\n",
       "         0.5       ,  0.5       ,  0.5       ,  0.57296734,  0.5       ,\n",
       "         0.55351614,  0.60238832,  0.5       ,  0.5       ,  0.18509509,\n",
       "         0.46680427,  0.5       ,  0.5       ,  0.5       ,  0.5       ,\n",
       "         0.26851442,  0.5       ,  0.61032483,  0.5       ,  0.5       ,\n",
       "         0.5       ,  0.5       ,  0.5       ,  0.5       ,  0.5       ,\n",
       "         0.5       ,  0.3501892 ,  0.5       ,  0.5       ]),\n",
       " 'split2_test_f1_macro': array([ 0.14141414,  0.14141414,  0.08888889,  0.17142857,  0.17142857,\n",
       "         0.18518519,  0.14141414,  0.17142857,  0.18518519,  0.32996633,\n",
       "         0.14141414,  0.16666667,  0.17142857,  0.15686275,  0.32996633,\n",
       "         0.18518519,  0.64631665,  0.19607843,  0.14141414,  0.34057971,\n",
       "         0.17142857,  0.41699346,  0.25811966,  0.47115385,  0.17142857,\n",
       "         0.18518519,  0.14141414,  0.17142857,  0.17142857,  0.17142857,\n",
       "         0.35573123,  0.17142857,  0.14141414,  0.17142857,  0.17142857,\n",
       "         0.14141414,  0.18518519,  0.18518519,  0.34343434,  0.17142857,\n",
       "         0.25416667,  0.16239316,  0.14141414,  0.14141414,  0.06060606,\n",
       "         0.39224138,  0.18518519,  0.14141414,  0.17142857,  0.17142857,\n",
       "         0.15079365,  0.17142857,  0.09195402,  0.18518519,  0.17142857,\n",
       "         0.17142857,  0.14141414,  0.14141414,  0.14141414,  0.17142857,\n",
       "         0.17142857,  0.4942029 ,  0.14141414,  0.14141414]),\n",
       " 'split2_test_f1_micro': array([ 0.26923077,  0.26923077,  0.15384615,  0.34615385,  0.34615385,\n",
       "         0.38461538,  0.26923077,  0.34615385,  0.38461538,  0.42307692,\n",
       "         0.26923077,  0.30769231,  0.34615385,  0.30769231,  0.42307692,\n",
       "         0.38461538,  0.61538462,  0.38461538,  0.26923077,  0.42307692,\n",
       "         0.34615385,  0.42307692,  0.34615385,  0.53846154,  0.34615385,\n",
       "         0.38461538,  0.26923077,  0.34615385,  0.34615385,  0.34615385,\n",
       "         0.46153846,  0.34615385,  0.26923077,  0.34615385,  0.34615385,\n",
       "         0.26923077,  0.38461538,  0.38461538,  0.46153846,  0.34615385,\n",
       "         0.38461538,  0.23076923,  0.26923077,  0.26923077,  0.07692308,\n",
       "         0.5       ,  0.38461538,  0.26923077,  0.34615385,  0.34615385,\n",
       "         0.19230769,  0.34615385,  0.15384615,  0.38461538,  0.34615385,\n",
       "         0.34615385,  0.26923077,  0.26923077,  0.26923077,  0.34615385,\n",
       "         0.34615385,  0.61538462,  0.26923077,  0.26923077]),\n",
       " 'split2_test_precision_macro': array([ 0.08974359,  0.08974359,  0.05797101,  0.11538462,  0.11538462,\n",
       "         0.12820513,  0.08974359,  0.11538462,  0.12820513,  0.45833333,\n",
       "         0.08974359,  0.11594203,  0.11538462,  0.11111111,  0.45833333,\n",
       "         0.12820513,  0.66329966,  0.13888889,  0.08974359,  0.29166667,\n",
       "         0.11538462,  0.40833333,  0.3236715 ,  0.39651416,  0.11538462,\n",
       "         0.12820513,  0.08974359,  0.11538462,  0.11538462,  0.11538462,\n",
       "         0.30769231,  0.12      ,  0.08974359,  0.11538462,  0.11538462,\n",
       "         0.08974359,  0.12820513,  0.12820513,  0.33333333,  0.11538462,\n",
       "         0.24154589,  0.18357488,  0.08974359,  0.08974359,  0.05555556,\n",
       "         0.41111111,  0.12820513,  0.08974359,  0.11538462,  0.11538462,\n",
       "         0.13535354,  0.11538462,  0.06060606,  0.12820513,  0.11538462,\n",
       "         0.11538462,  0.08974359,  0.08974359,  0.08974359,  0.11538462,\n",
       "         0.11538462,  0.41025641,  0.08974359,  0.08974359]),\n",
       " 'split2_test_precision_micro': array([ 0.26923077,  0.26923077,  0.15384615,  0.34615385,  0.34615385,\n",
       "         0.38461538,  0.26923077,  0.34615385,  0.38461538,  0.42307692,\n",
       "         0.26923077,  0.30769231,  0.34615385,  0.30769231,  0.42307692,\n",
       "         0.38461538,  0.61538462,  0.38461538,  0.26923077,  0.42307692,\n",
       "         0.34615385,  0.42307692,  0.34615385,  0.53846154,  0.34615385,\n",
       "         0.38461538,  0.26923077,  0.34615385,  0.34615385,  0.34615385,\n",
       "         0.46153846,  0.34615385,  0.26923077,  0.34615385,  0.34615385,\n",
       "         0.26923077,  0.38461538,  0.38461538,  0.46153846,  0.34615385,\n",
       "         0.38461538,  0.23076923,  0.26923077,  0.26923077,  0.07692308,\n",
       "         0.5       ,  0.38461538,  0.26923077,  0.34615385,  0.34615385,\n",
       "         0.19230769,  0.34615385,  0.15384615,  0.38461538,  0.34615385,\n",
       "         0.34615385,  0.26923077,  0.26923077,  0.26923077,  0.34615385,\n",
       "         0.34615385,  0.61538462,  0.26923077,  0.26923077]),\n",
       " 'split3_test_accuracy': array([ 0.26923077,  0.38461538,  0.34615385,  0.38461538,  0.38461538,\n",
       "         0.26923077,  0.34615385,  0.38461538,  0.38461538,  0.38461538,\n",
       "         0.38461538,  0.38461538,  0.26923077,  0.5       ,  0.38461538,\n",
       "         0.34615385,  0.38461538,  0.34615385,  0.26923077,  0.34615385,\n",
       "         0.34615385,  0.26923077,  0.38461538,  0.38461538,  0.26923077,\n",
       "         0.26923077,  0.26923077,  0.34615385,  0.46153846,  0.38461538,\n",
       "         0.34615385,  0.34615385,  0.23076923,  0.38461538,  0.26923077,\n",
       "         0.26923077,  0.30769231,  0.34615385,  0.26923077,  0.38461538,\n",
       "         0.34615385,  0.38461538,  0.34615385,  0.42307692,  0.38461538,\n",
       "         0.19230769,  0.38461538,  0.34615385,  0.34615385,  0.38461538,\n",
       "         0.26923077,  0.38461538,  0.26923077,  0.38461538,  0.26923077,\n",
       "         0.34615385,  0.38461538,  0.19230769,  0.26923077,  0.34615385,\n",
       "         0.23076923,  0.34615385,  0.46153846,  0.38461538]),\n",
       " 'split3_test_au_prc_macro': array([ 0.5       ,  0.5       ,  0.5       ,  0.5       ,  0.5       ,\n",
       "         0.5       ,  0.3945157 ,  0.5       ,  0.5       ,  0.5       ,\n",
       "         0.5       ,  0.50154799,  0.5       ,  0.54238538,  0.5       ,\n",
       "         0.5       ,  0.65271021,  0.5       ,  0.5       ,  0.5       ,\n",
       "         0.5       ,  0.5       ,  0.5       ,  0.5       ,  0.5       ,\n",
       "         0.5       ,  0.5       ,  0.5       ,  0.73942208,  0.5       ,\n",
       "         0.5       ,  0.5       ,  0.44957983,  0.5       ,  0.5       ,\n",
       "         0.5       ,  0.45906433,  0.5       ,  0.5       ,  0.5       ,\n",
       "         0.5       ,  0.5       ,  0.5       ,  0.44957983,  0.5       ,\n",
       "         0.38967517,  0.44957983,  0.5       ,  0.5       ,  0.5       ,\n",
       "         0.5       ,  0.5       ,  0.5       ,  0.5       ,  0.5       ,\n",
       "         0.50154799,  0.5       ,  0.41190845,  0.5       ,  0.5       ,\n",
       "         0.55042017,  0.5       ,  0.5487739 ,  0.5       ]),\n",
       " 'split3_test_au_prc_micro': array([ 0.5       ,  0.5       ,  0.5       ,  0.5       ,  0.5       ,\n",
       "         0.5       ,  0.3945157 ,  0.5       ,  0.5       ,  0.5       ,\n",
       "         0.5       ,  0.50154799,  0.5       ,  0.54238538,  0.5       ,\n",
       "         0.5       ,  0.65271021,  0.5       ,  0.5       ,  0.5       ,\n",
       "         0.5       ,  0.5       ,  0.5       ,  0.5       ,  0.5       ,\n",
       "         0.5       ,  0.5       ,  0.5       ,  0.73942208,  0.5       ,\n",
       "         0.5       ,  0.5       ,  0.44957983,  0.5       ,  0.5       ,\n",
       "         0.5       ,  0.45906433,  0.5       ,  0.5       ,  0.5       ,\n",
       "         0.5       ,  0.5       ,  0.5       ,  0.44957983,  0.5       ,\n",
       "         0.38967517,  0.44957983,  0.5       ,  0.5       ,  0.5       ,\n",
       "         0.5       ,  0.5       ,  0.5       ,  0.5       ,  0.5       ,\n",
       "         0.50154799,  0.5       ,  0.41190845,  0.5       ,  0.5       ,\n",
       "         0.55042017,  0.5       ,  0.5487739 ,  0.5       ]),\n",
       " 'split3_test_f1_macro': array([ 0.14141414,  0.18518519,  0.17142857,  0.18518519,  0.18518519,\n",
       "         0.14141414,  0.26164875,  0.18518519,  0.18518519,  0.18518519,\n",
       "         0.18518519,  0.23707665,  0.14141414,  0.38814815,  0.18518519,\n",
       "         0.17142857,  0.2545156 ,  0.17142857,  0.14141414,  0.17142857,\n",
       "         0.17142857,  0.14141414,  0.18518519,  0.18518519,  0.14141414,\n",
       "         0.14141414,  0.14141414,  0.17142857,  0.36437247,  0.18518519,\n",
       "         0.17142857,  0.17142857,  0.125     ,  0.18518519,  0.14141414,\n",
       "         0.14141414,  0.15686275,  0.17142857,  0.14141414,  0.18518519,\n",
       "         0.17142857,  0.18518519,  0.17142857,  0.27380952,  0.18518519,\n",
       "         0.14323607,  0.19047619,  0.17142857,  0.17142857,  0.18518519,\n",
       "         0.14141414,  0.18518519,  0.14141414,  0.18518519,  0.14141414,\n",
       "         0.17647059,  0.18518519,  0.16333333,  0.14141414,  0.17142857,\n",
       "         0.125     ,  0.17142857,  0.35333333,  0.18518519]),\n",
       " 'split3_test_f1_micro': array([ 0.26923077,  0.38461538,  0.34615385,  0.38461538,  0.38461538,\n",
       "         0.26923077,  0.34615385,  0.38461538,  0.38461538,  0.38461538,\n",
       "         0.38461538,  0.38461538,  0.26923077,  0.5       ,  0.38461538,\n",
       "         0.34615385,  0.38461538,  0.34615385,  0.26923077,  0.34615385,\n",
       "         0.34615385,  0.26923077,  0.38461538,  0.38461538,  0.26923077,\n",
       "         0.26923077,  0.26923077,  0.34615385,  0.46153846,  0.38461538,\n",
       "         0.34615385,  0.34615385,  0.23076923,  0.38461538,  0.26923077,\n",
       "         0.26923077,  0.30769231,  0.34615385,  0.26923077,  0.38461538,\n",
       "         0.34615385,  0.38461538,  0.34615385,  0.42307692,  0.38461538,\n",
       "         0.19230769,  0.38461538,  0.34615385,  0.34615385,  0.38461538,\n",
       "         0.26923077,  0.38461538,  0.26923077,  0.38461538,  0.26923077,\n",
       "         0.34615385,  0.38461538,  0.19230769,  0.26923077,  0.34615385,\n",
       "         0.23076923,  0.34615385,  0.46153846,  0.38461538]),\n",
       " 'split3_test_precision_macro': array([ 0.08974359,  0.12820513,  0.11538462,  0.12820513,  0.12820513,\n",
       "         0.08974359,  0.24444444,  0.12820513,  0.12820513,  0.12820513,\n",
       "         0.12820513,  0.45333333,  0.08974359,  0.32121212,  0.12820513,\n",
       "         0.11538462,  0.20551378,  0.11538462,  0.08974359,  0.11538462,\n",
       "         0.11538462,  0.08974359,  0.12820513,  0.12820513,  0.08974359,\n",
       "         0.08974359,  0.08974359,  0.11538462,  0.325     ,  0.12820513,\n",
       "         0.11538462,  0.11538462,  0.08      ,  0.12820513,  0.08974359,\n",
       "         0.08974359,  0.10666667,  0.11538462,  0.08974359,  0.12820513,\n",
       "         0.11538462,  0.12820513,  0.11538462,  0.46666667,  0.12820513,\n",
       "         0.14393939,  0.13333333,  0.11538462,  0.11538462,  0.12820513,\n",
       "         0.08974359,  0.12820513,  0.08974359,  0.12820513,  0.08974359,\n",
       "         0.12      ,  0.12820513,  0.16666667,  0.08974359,  0.11538462,\n",
       "         0.08      ,  0.11538462,  0.30707071,  0.12820513]),\n",
       " 'split3_test_precision_micro': array([ 0.26923077,  0.38461538,  0.34615385,  0.38461538,  0.38461538,\n",
       "         0.26923077,  0.34615385,  0.38461538,  0.38461538,  0.38461538,\n",
       "         0.38461538,  0.38461538,  0.26923077,  0.5       ,  0.38461538,\n",
       "         0.34615385,  0.38461538,  0.34615385,  0.26923077,  0.34615385,\n",
       "         0.34615385,  0.26923077,  0.38461538,  0.38461538,  0.26923077,\n",
       "         0.26923077,  0.26923077,  0.34615385,  0.46153846,  0.38461538,\n",
       "         0.34615385,  0.34615385,  0.23076923,  0.38461538,  0.26923077,\n",
       "         0.26923077,  0.30769231,  0.34615385,  0.26923077,  0.38461538,\n",
       "         0.34615385,  0.38461538,  0.34615385,  0.42307692,  0.38461538,\n",
       "         0.19230769,  0.38461538,  0.34615385,  0.34615385,  0.38461538,\n",
       "         0.26923077,  0.38461538,  0.26923077,  0.38461538,  0.26923077,\n",
       "         0.34615385,  0.38461538,  0.19230769,  0.26923077,  0.34615385,\n",
       "         0.23076923,  0.34615385,  0.46153846,  0.38461538]),\n",
       " 'split4_test_accuracy': array([ 0.26923077,  0.34615385,  0.34615385,  0.23076923,  0.38461538,\n",
       "         0.42307692,  0.38461538,  0.34615385,  0.26923077,  0.38461538,\n",
       "         0.34615385,  0.38461538,  0.34615385,  0.38461538,  0.38461538,\n",
       "         0.26923077,  0.38461538,  0.34615385,  0.07692308,  0.38461538,\n",
       "         0.34615385,  0.34615385,  0.34615385,  0.26923077,  0.34615385,\n",
       "         0.38461538,  0.34615385,  0.34615385,  0.26923077,  0.38461538,\n",
       "         0.42307692,  0.38461538,  0.34615385,  0.34615385,  0.34615385,\n",
       "         0.26923077,  0.38461538,  0.26923077,  0.26923077,  0.26923077,\n",
       "         0.26923077,  0.38461538,  0.23076923,  0.26923077,  0.34615385,\n",
       "         0.34615385,  0.26923077,  0.26923077,  0.38461538,  0.26923077,\n",
       "         0.30769231,  0.34615385,  0.38461538,  0.5       ,  0.26923077,\n",
       "         0.34615385,  0.38461538,  0.38461538,  0.38461538,  0.42307692,\n",
       "         0.34615385,  0.26923077,  0.34615385,  0.26923077]),\n",
       " 'split4_test_au_prc_macro': array([ 0.5       ,  0.5       ,  0.5       ,  0.4054499 ,  0.5       ,\n",
       "         0.7662293 ,  0.5       ,  0.5       ,  0.5       ,  0.5       ,\n",
       "         0.5       ,  0.5       ,  0.5       ,  0.5       ,  0.5       ,\n",
       "         0.5       ,  0.5       ,  0.5       ,  0.22448278,  0.5       ,\n",
       "         0.5       ,  0.5       ,  0.5       ,  0.5       ,  0.5       ,\n",
       "         0.36296624,  0.49845201,  0.5       ,  0.5       ,  0.5       ,\n",
       "         0.56929087,  0.5       ,  0.5       ,  0.5       ,  0.5       ,\n",
       "         0.5       ,  0.5       ,  0.5       ,  0.49845201,  0.5       ,\n",
       "         0.5       ,  0.5       ,  0.44009534,  0.5       ,  0.5       ,\n",
       "         0.5       ,  0.5       ,  0.5       ,  0.5       ,  0.5       ,\n",
       "         0.62135731,  0.5       ,  0.5       ,  0.65119396,  0.41812865,\n",
       "         0.5       ,  0.5       ,  0.54093567,  0.5       ,  0.57373683,\n",
       "         0.5       ,  0.5       ,  0.51896899,  0.5       ]),\n",
       " 'split4_test_au_prc_micro': array([ 0.5       ,  0.5       ,  0.5       ,  0.4054499 ,  0.5       ,\n",
       "         0.7662293 ,  0.5       ,  0.5       ,  0.5       ,  0.5       ,\n",
       "         0.5       ,  0.5       ,  0.5       ,  0.5       ,  0.5       ,\n",
       "         0.5       ,  0.5       ,  0.5       ,  0.22448278,  0.5       ,\n",
       "         0.5       ,  0.5       ,  0.5       ,  0.5       ,  0.5       ,\n",
       "         0.36296624,  0.49845201,  0.5       ,  0.5       ,  0.5       ,\n",
       "         0.56929087,  0.5       ,  0.5       ,  0.5       ,  0.5       ,\n",
       "         0.5       ,  0.5       ,  0.5       ,  0.49845201,  0.5       ,\n",
       "         0.5       ,  0.5       ,  0.44009534,  0.5       ,  0.5       ,\n",
       "         0.5       ,  0.5       ,  0.5       ,  0.5       ,  0.5       ,\n",
       "         0.62135731,  0.5       ,  0.5       ,  0.65119396,  0.41812865,\n",
       "         0.5       ,  0.5       ,  0.54093567,  0.5       ,  0.57373683,\n",
       "         0.5       ,  0.5       ,  0.51896899,  0.5       ]),\n",
       " 'split4_test_f1_macro': array([ 0.14141414,  0.17142857,  0.17142857,  0.18787879,  0.18518519,\n",
       "         0.31333333,  0.18518519,  0.17142857,  0.14141414,  0.18518519,\n",
       "         0.17142857,  0.18518519,  0.17142857,  0.18518519,  0.18518519,\n",
       "         0.14141414,  0.18518519,  0.17142857,  0.06588235,  0.18518519,\n",
       "         0.17142857,  0.17142857,  0.17142857,  0.14141414,  0.17142857,\n",
       "         0.3115942 ,  0.17142857,  0.17142857,  0.14141414,  0.18518519,\n",
       "         0.31111111,  0.18518519,  0.17142857,  0.17142857,  0.17142857,\n",
       "         0.14141414,  0.18518519,  0.14141414,  0.14583333,  0.14141414,\n",
       "         0.14141414,  0.18518519,  0.16666667,  0.14141414,  0.17142857,\n",
       "         0.17142857,  0.14141414,  0.14141414,  0.18518519,  0.14141414,\n",
       "         0.20588235,  0.17142857,  0.18518519,  0.44941176,  0.14141414,\n",
       "         0.17142857,  0.18518519,  0.19047619,  0.18518519,  0.42879257,\n",
       "         0.17142857,  0.14141414,  0.27174976,  0.14141414]),\n",
       " 'split4_test_f1_micro': array([ 0.26923077,  0.34615385,  0.34615385,  0.23076923,  0.38461538,\n",
       "         0.42307692,  0.38461538,  0.34615385,  0.26923077,  0.38461538,\n",
       "         0.34615385,  0.38461538,  0.34615385,  0.38461538,  0.38461538,\n",
       "         0.26923077,  0.38461538,  0.34615385,  0.07692308,  0.38461538,\n",
       "         0.34615385,  0.34615385,  0.34615385,  0.26923077,  0.34615385,\n",
       "         0.38461538,  0.34615385,  0.34615385,  0.26923077,  0.38461538,\n",
       "         0.42307692,  0.38461538,  0.34615385,  0.34615385,  0.34615385,\n",
       "         0.26923077,  0.38461538,  0.26923077,  0.26923077,  0.26923077,\n",
       "         0.26923077,  0.38461538,  0.23076923,  0.26923077,  0.34615385,\n",
       "         0.34615385,  0.26923077,  0.26923077,  0.38461538,  0.26923077,\n",
       "         0.30769231,  0.34615385,  0.38461538,  0.5       ,  0.26923077,\n",
       "         0.34615385,  0.38461538,  0.38461538,  0.38461538,  0.42307692,\n",
       "         0.34615385,  0.26923077,  0.34615385,  0.26923077]),\n",
       " 'split4_test_precision_macro': array([ 0.08974359,  0.11538462,  0.11538462,  0.15384615,  0.12820513,\n",
       "         0.26666667,  0.12820513,  0.11538462,  0.08974359,  0.12820513,\n",
       "         0.11538462,  0.12820513,  0.11538462,  0.12820513,  0.12820513,\n",
       "         0.08974359,  0.12820513,  0.11538462,  0.05416667,  0.12820513,\n",
       "         0.11538462,  0.11538462,  0.11538462,  0.08974359,  0.11538462,\n",
       "         0.25641026,  0.12      ,  0.11538462,  0.08974359,  0.12820513,\n",
       "         0.3       ,  0.12820513,  0.11538462,  0.11538462,  0.11538462,\n",
       "         0.08974359,  0.12820513,  0.08974359,  0.09333333,  0.08974359,\n",
       "         0.08974359,  0.12820513,  0.18357488,  0.08974359,  0.11538462,\n",
       "         0.11538462,  0.08974359,  0.08974359,  0.12820513,  0.08974359,\n",
       "         0.17042607,  0.11538462,  0.12820513,  0.7010582 ,  0.09722222,\n",
       "         0.11538462,  0.12820513,  0.13333333,  0.12820513,  0.42592593,\n",
       "         0.11538462,  0.08974359,  0.27272727,  0.08974359]),\n",
       " 'split4_test_precision_micro': array([ 0.26923077,  0.34615385,  0.34615385,  0.23076923,  0.38461538,\n",
       "         0.42307692,  0.38461538,  0.34615385,  0.26923077,  0.38461538,\n",
       "         0.34615385,  0.38461538,  0.34615385,  0.38461538,  0.38461538,\n",
       "         0.26923077,  0.38461538,  0.34615385,  0.07692308,  0.38461538,\n",
       "         0.34615385,  0.34615385,  0.34615385,  0.26923077,  0.34615385,\n",
       "         0.38461538,  0.34615385,  0.34615385,  0.26923077,  0.38461538,\n",
       "         0.42307692,  0.38461538,  0.34615385,  0.34615385,  0.34615385,\n",
       "         0.26923077,  0.38461538,  0.26923077,  0.26923077,  0.26923077,\n",
       "         0.26923077,  0.38461538,  0.23076923,  0.26923077,  0.34615385,\n",
       "         0.34615385,  0.26923077,  0.26923077,  0.38461538,  0.26923077,\n",
       "         0.30769231,  0.34615385,  0.38461538,  0.5       ,  0.26923077,\n",
       "         0.34615385,  0.38461538,  0.38461538,  0.38461538,  0.42307692,\n",
       "         0.34615385,  0.26923077,  0.34615385,  0.26923077]),\n",
       " 'std_fit_time': array([ 0.00631822,  0.31268702,  0.10787279,  0.03831511,  0.21501712,\n",
       "         0.0326969 ,  0.00318405,  0.16530147,  0.10015909,  0.24241159,\n",
       "         0.00081386,  0.09858061,  0.03650269,  0.12762902,  0.11359368,\n",
       "         0.22099951,  0.27537097,  0.03768158,  0.07679024,  0.1347883 ,\n",
       "         0.0009023 ,  0.01293555,  0.06159693,  0.18135575,  0.15633851,\n",
       "         0.13855713,  0.1280348 ,  0.09641701,  0.1307374 ,  0.03423779,\n",
       "         0.00187961,  0.02910467,  0.05153023,  0.01739699,  0.11697345,\n",
       "         0.00369472,  0.18770264,  0.00250969,  0.13634555,  0.16435523,\n",
       "         0.15166086,  0.12078383,  0.00070526,  0.10348173,  0.05379572,\n",
       "         0.00895818,  0.17206668,  0.00912981,  0.01318241,  0.00189505,\n",
       "         0.00057195,  0.00325581,  0.00235785,  0.0203944 ,  0.00273513,\n",
       "         0.00516806,  0.08834943,  0.1940969 ,  0.00038247,  0.00646646,\n",
       "         0.0064972 ,  0.00695026,  0.00453112,  0.01092452]),\n",
       " 'std_score_time': array([ 0.01110664,  0.0073849 ,  0.00476489,  0.00636953,  0.00316803,\n",
       "         0.00276734,  0.0071907 ,  0.00887479,  0.00086511,  0.00069157,\n",
       "         0.00076006,  0.00147188,  0.00163979,  0.00134469,  0.00107335,\n",
       "         0.00049544,  0.00596137,  0.0073064 ,  0.00526972,  0.0032189 ,\n",
       "         0.0014125 ,  0.00323508,  0.00073559,  0.00200211,  0.00392073,\n",
       "         0.0005894 ,  0.00096607,  0.0019048 ,  0.00195636,  0.00198522,\n",
       "         0.00176656,  0.00268765,  0.00215469,  0.00239517,  0.00248495,\n",
       "         0.00202655,  0.00105519,  0.00097541,  0.00136118,  0.00082819,\n",
       "         0.00079209,  0.0017815 ,  0.00050064,  0.00046807,  0.00303977,\n",
       "         0.00205309,  0.00309116,  0.00089526,  0.00188385,  0.00043229,\n",
       "         0.00204479,  0.00186497,  0.0024711 ,  0.00205931,  0.00142762,\n",
       "         0.00252813,  0.00094783,  0.00184664,  0.00123409,  0.00186818,\n",
       "         0.00099098,  0.00154424,  0.00181041,  0.00162133]),\n",
       " 'std_test_accuracy': array([ 0.03241722,  0.13232441,  0.08302867,  0.05368462,  0.01765368,\n",
       "         0.0505804 ,  0.04207285,  0.01619151,  0.06850208,  0.05028602,\n",
       "         0.04910308,  0.09652315,  0.04354593,  0.06402099,  0.06560968,\n",
       "         0.08186403,  0.09337416,  0.07393261,  0.13964543,  0.0612727 ,\n",
       "         0.04065161,  0.0822453 ,  0.02572176,  0.11089375,  0.02940952,\n",
       "         0.04396494,  0.0927567 ,  0.00987186,  0.07173812,  0.02375034,\n",
       "         0.07937861,  0.03829175,  0.05873196,  0.02031598,  0.03405701,\n",
       "         0.04413764,  0.02891743,  0.10263697,  0.08534758,  0.04546589,\n",
       "         0.04207285,  0.06239055,  0.07559776,  0.06241343,  0.11181136,\n",
       "         0.09713286,  0.05804634,  0.06113164,  0.09489606,  0.05856068,\n",
       "         0.06905728,  0.0457301 ,  0.08886063,  0.04891453,  0.03117205,\n",
       "         0.08262292,  0.04265691,  0.07124208,  0.04339622,  0.0668769 ,\n",
       "         0.08120727,  0.11651113,  0.11157768,  0.05196194]),\n",
       " 'std_test_au_prc_macro': array([ 0.        ,  0.09210478,  0.05981627,  0.03739002,  0.        ,\n",
       "         0.1052809 ,  0.04171397,  0.        ,  0.01261725,  0.03987751,\n",
       "         0.        ,  0.07405668,  0.00088481,  0.01709747,  0.03987751,\n",
       "         0.0754713 ,  0.09192282,  0.09565632,  0.12954951,  0.09065638,\n",
       "         0.        ,  0.05957565,  0.01473144,  0.13769664,  0.03008363,\n",
       "         0.05419027,  0.09159614,  0.        ,  0.09467994,  0.02528516,\n",
       "         0.03881159,  0.00061215,  0.01993876,  0.02313153,  0.        ,\n",
       "         0.        ,  0.01618809,  0.08696444,  0.05251136,  0.04424063,\n",
       "         0.02116306,  0.04585655,  0.03661955,  0.02391938,  0.12452977,\n",
       "         0.05890211,  0.02039288,  0.01210766,  0.10200626,  0.04147051,\n",
       "         0.11312911,  0.11414083,  0.04362817,  0.07793915,  0.03237619,\n",
       "         0.06204979,  0.        ,  0.04179857,  0.02047709,  0.04826323,\n",
       "         0.03772898,  0.05924298,  0.10388314,  0.        ]),\n",
       " 'std_test_au_prc_micro': array([ 0.        ,  0.09210478,  0.05981627,  0.03739002,  0.        ,\n",
       "         0.1052809 ,  0.04171397,  0.        ,  0.01261725,  0.03987751,\n",
       "         0.        ,  0.07405668,  0.00088481,  0.01709747,  0.03987751,\n",
       "         0.0754713 ,  0.09192282,  0.09565632,  0.12954951,  0.09065638,\n",
       "         0.        ,  0.05957565,  0.01473144,  0.13769664,  0.03008363,\n",
       "         0.05419027,  0.09159614,  0.        ,  0.09467994,  0.02528516,\n",
       "         0.03881159,  0.00061215,  0.01993876,  0.02313153,  0.        ,\n",
       "         0.        ,  0.01618809,  0.08696444,  0.05251136,  0.04424063,\n",
       "         0.02116306,  0.04585655,  0.03661955,  0.02391938,  0.12452977,\n",
       "         0.05890211,  0.02039288,  0.01210766,  0.10200626,  0.04147051,\n",
       "         0.11312911,  0.11414083,  0.04362817,  0.07793915,  0.03237619,\n",
       "         0.06204979,  0.        ,  0.04179857,  0.02047709,  0.04826323,\n",
       "         0.03772898,  0.05924298,  0.10388314,  0.        ]),\n",
       " 'std_test_f1_macro': array([ 0.01270166,  0.19538993,  0.03509524,  0.00694107,  0.00632275,\n",
       "         0.05779278,  0.03856964,  0.00580493,  0.08588888,  0.06407384,\n",
       "         0.01880663,  0.16188784,  0.03474312,  0.08549722,  0.06930617,\n",
       "         0.09782823,  0.17858285,  0.09779968,  0.14644052,  0.10810365,\n",
       "         0.01572934,  0.11765259,  0.03484557,  0.14581522,  0.03899529,\n",
       "         0.05713223,  0.1219253 ,  0.00356877,  0.08382806,  0.07718253,\n",
       "         0.09091564,  0.01452908,  0.02300132,  0.03649788,  0.01315003,\n",
       "         0.01702366,  0.01066577,  0.03642001,  0.08951295,  0.02028292,\n",
       "         0.03656324,  0.07830472,  0.03424551,  0.05508448,  0.04547975,\n",
       "         0.0892879 ,  0.06553828,  0.04729698,  0.12272897,  0.07120023,\n",
       "         0.02307398,  0.05655633,  0.03578422,  0.11527997,  0.01219822,\n",
       "         0.14375821,  0.01619699,  0.01640809,  0.03306093,  0.09948377,\n",
       "         0.0975401 ,  0.13033478,  0.12273832,  0.01976679]),\n",
       " 'std_test_f1_micro': array([ 0.03241722,  0.13232441,  0.08302867,  0.05368462,  0.01765368,\n",
       "         0.0505804 ,  0.04207285,  0.01619151,  0.06850208,  0.05028602,\n",
       "         0.04910308,  0.09652315,  0.04354593,  0.06402099,  0.06560968,\n",
       "         0.08186403,  0.09337416,  0.07393261,  0.13964543,  0.0612727 ,\n",
       "         0.04065161,  0.0822453 ,  0.02572176,  0.11089375,  0.02940952,\n",
       "         0.04396494,  0.0927567 ,  0.00987186,  0.07173812,  0.02375034,\n",
       "         0.07937861,  0.03829175,  0.05873196,  0.02031598,  0.03405701,\n",
       "         0.04413764,  0.02891743,  0.10263697,  0.08534758,  0.04546589,\n",
       "         0.04207285,  0.06239055,  0.07559776,  0.06241343,  0.11181136,\n",
       "         0.09713286,  0.05804634,  0.06113164,  0.09489606,  0.05856068,\n",
       "         0.06905728,  0.0457301 ,  0.08886063,  0.04891453,  0.03117205,\n",
       "         0.08262292,  0.04265691,  0.07124208,  0.04339622,  0.0668769 ,\n",
       "         0.08120727,  0.11651113,  0.11157768,  0.05196194]),\n",
       " 'std_test_precision_macro': array([ 0.01080574,  0.22098471,  0.02506856,  0.01415186,  0.00588456,\n",
       "         0.06071093,  0.05219947,  0.00539717,  0.12056935,  0.1355816 ,\n",
       "         0.01636769,  0.20426406,  0.14173172,  0.08005519,  0.13963743,\n",
       "         0.12768185,  0.20716648,  0.0991679 ,  0.24172865,  0.12460146,\n",
       "         0.01355054,  0.16466199,  0.08102732,  0.13556155,  0.12778101,\n",
       "         0.0567721 ,  0.15151839,  0.00329062,  0.08908492,  0.10493189,\n",
       "         0.10101666,  0.01296003,  0.01867835,  0.05657288,  0.01135234,\n",
       "         0.01471255,  0.0080484 ,  0.01937291,  0.12437609,  0.03103927,\n",
       "         0.05198213,  0.12330902,  0.04696095,  0.14559951,  0.02646653,\n",
       "         0.11246993,  0.14196862,  0.06542744,  0.13065094,  0.08850533,\n",
       "         0.02544477,  0.06093026,  0.0264287 ,  0.22022365,  0.01014049,\n",
       "         0.18663526,  0.01421897,  0.02477389,  0.04415702,  0.11823305,\n",
       "         0.11147655,  0.11882904,  0.11726831,  0.01732065]),\n",
       " 'std_test_precision_micro': array([ 0.03241722,  0.13232441,  0.08302867,  0.05368462,  0.01765368,\n",
       "         0.0505804 ,  0.04207285,  0.01619151,  0.06850208,  0.05028602,\n",
       "         0.04910308,  0.09652315,  0.04354593,  0.06402099,  0.06560968,\n",
       "         0.08186403,  0.09337416,  0.07393261,  0.13964543,  0.0612727 ,\n",
       "         0.04065161,  0.0822453 ,  0.02572176,  0.11089375,  0.02940952,\n",
       "         0.04396494,  0.0927567 ,  0.00987186,  0.07173812,  0.02375034,\n",
       "         0.07937861,  0.03829175,  0.05873196,  0.02031598,  0.03405701,\n",
       "         0.04413764,  0.02891743,  0.10263697,  0.08534758,  0.04546589,\n",
       "         0.04207285,  0.06239055,  0.07559776,  0.06241343,  0.11181136,\n",
       "         0.09713286,  0.05804634,  0.06113164,  0.09489606,  0.05856068,\n",
       "         0.06905728,  0.0457301 ,  0.08886063,  0.04891453,  0.03117205,\n",
       "         0.08262292,  0.04265691,  0.07124208,  0.04339622,  0.0668769 ,\n",
       "         0.08120727,  0.11651113,  0.11157768,  0.05196194])}"
      ]
     },
     "execution_count": 718,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 721,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 723,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('reduce_dim', PCA(copy=True, iterated_power='auto', n_components=5, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)), ('classify', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.set_params(**components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 730,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_test = pipe.fit(X_train, y_train).predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LogisticRegression(**a).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LogisticRegression(**a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dum_true = pd.get_dummies(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dum_pred = pd.get_dummies(lr_model.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97500000000000009"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(dum_true, dum_pred, average='micro', sample_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#AUPRC in multilabel settings\n",
    "#http://scikit-learn.org/stable/auto_examples/model_selection/plot_precision_recall.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot precision recall curves for multiclass\n",
    "\"\"\"\n",
    "\n",
    "from itertools import cycle\n",
    "# setup plot details\n",
    "colors = cycle(['navy', 'turquoise', 'darkorange', 'cornflowerblue', 'teal'])\n",
    "\n",
    "plt.figure(figsize=(7, 8))\n",
    "f_scores = np.linspace(0.2, 0.8, num=4)\n",
    "lines = []\n",
    "labels = []\n",
    "for f_score in f_scores:\n",
    "    x = np.linspace(0.01, 1)\n",
    "    y = f_score * x / (2 * x - f_score)\n",
    "    l, = plt.plot(x[y >= 0], y[y >= 0], color='gray', alpha=0.2)\n",
    "    plt.annotate('f1={0:0.1f}'.format(f_score), xy=(0.9, y[45] + 0.02))\n",
    "\n",
    "lines.append(l)\n",
    "labels.append('iso-f1 curves')\n",
    "l, = plt.plot(recall[\"micro\"], precision[\"micro\"], color='gold', lw=2)\n",
    "lines.append(l)\n",
    "labels.append('micro-average Precision-recall (area = {0:0.2f})'\n",
    "              ''.format(average_precision[\"micro\"]))\n",
    "\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    l, = plt.plot(recall[i], precision[i], color=color, lw=2)\n",
    "    lines.append(l)\n",
    "    labels.append('Precision-recall for class {0} (area = {1:0.2f})'\n",
    "                  ''.format(i, average_precision[i]))\n",
    "\n",
    "fig = plt.gcf()\n",
    "fig.subplots_adjust(bottom=0.25)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Extension of Precision-Recall curve to multi-class')\n",
    "plt.legend(lines, labels, loc=(0, -.38), prop=dict(size=14))\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reading from log\n",
    "import ast\n",
    "results=pd.read_csv('results.csv').head(10)\n",
    "res=results.iloc[1]['params'].replace('\\n','').strip()\n",
    "res=\" \".join(res.split())\n",
    "ast.literal_eval(res)\n",
    "res.named_steps\n",
    "a={'classify': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True, intercept_scaling=1, max_iter=10000, multi_class='ovr', n_jobs=1, penalty='l2', random_state=None, solver='saga', tol=0.0001, verbose=0, warm_start=False), 'classify__C': 1, 'classify__max_iter': 10000, 'classify__penalty': 'l2', 'classify__solver': 'saga', 'reduce_dim': PCA(copy=True, iterated_power='auto', n_components=30, random_state=None, svd_solver='auto', tol=0.0, whiten=False), 'reduce_dim__n_components': 30}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
